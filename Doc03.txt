Palabras del documento Doc03.txt

deteccion
clasificacion
zeroday
malware
traves
data
mining
machine
learning
tamano
dado
constante
incremento
numero
complejidad
ataques
informaticos
mecanismos
convencionales
deteccion
resultan
ineficientes
mayoria
escenarios
contexto
presente
investigacion
propone
determinar
tecnicas
data
mining
machine
learning
pueden
ser
utilizadas
efectivamente
entrenamiento
algoritmos
capaces
detectar
clasificar
correctamente
nuevos
tipos
amenazas
machine
learning
malware
seguridad
informatica
virus
zeroday
data
mining
inteligencia
artificial
redes
neuronales
cuenta
resultados
obtenidos
posible
afirmar
utilizacion
tecnicas
data
mining
machine
learning
clasificar
familias
malware
resultado
efectiva
cuanto
problematica
deteccion
cree
que
contar
conjunto
datos
considerablemente
mas
grande
algoritmos
podrian
lograr
resultados
ampliamente
superiores
tareas
clasificacion
partir
conjunto
once
mil
muestras
malwares
construyo
dataset
conformado
atributos
considerados
mas
relevantes
cada
familia
datos
implementaron
ejecutaron
distintos
algoritmos
machine
learning
clasificacion
cuanto
deteccion
malware
aplicaron
mismas
tecnicas
tareas
clasificacion
utilizando
datos
partida
programas
considerados
benignos
cuales
ser
desensamblados
cuanto
tarea
clasificacion
malware
puede
extender
trabajo
realizado
comprendiendo
mayor
numero
familias
mayor
cantidad
muestras
aquellas
familias
menos
observaciones
deteccion
malware
recomienda
volver
ejecutar
algoritmos
aqui
implementados
cantidad
significativamente
mayor
archivos
benignos
conjunto
datos
octubre
augusto
recordon
silvia
ruiz
diaz
licenciatura
sistemas
dra
claudia
pons
facultad
inform
atica
universidad
nacional
plata
detecci
on
clasificaci
on
zeroday
malware
traves
data
mining
machine
learning
tesina
grado
autores
augusto
recordon
silvia
ruiz
diaz
directora
dra
claudia
pons
octubre
ii
success
is
not
ﬁnal
failure
is
not
fatal
it
is
the
courage
to
continue
that
counts
sir
winston
churchill
iii
universidad
nacional
plata
facultad
informatica
resumen
tesis
licenciatura
sistemas
detecci
on
clasificaci
on
zeroday
malware
traves
data
mining
machine
learning
augusto
recordon
silvia
ruiz
diaz
estudios
sugieren
que
ultimos
anos
incremento
exponencial
ataques
informaticos
causando
organizaciones
perdidas
ﬁ
nancieras
orden
millones
mientras
muchas
companıas
dedican
tiempo
recursos
desarrollo
antivirus
complejidad
velocidad
propagacion
capacidad
polimorﬁca
poseen
virus
modernos
representan
enormes
desafıos
empresas
motivados
encontrar
nuevas
alternativas
comunidad
cientıﬁcos
datos
descubierto
utilizacion
tecnicas
machine
learning
deep
learning
deteccion
clasiﬁcacion
malware
puede
ofrecer
opcion
mas
competitiva
investigacion
comenzara
realizando
extrac
cion
informacion
conjunto
datos
compuesto
once
mil
archivos
asm
bytes
correspondientes
nueve
familias
distintas
malwares
luego
median
implementacion
algoritmos
machine
learning
intentara
clasiﬁcar
malwares
correspondientes
familias
forma
complementaria
realizara
clasiﬁcacion
binaria
deteccion
malwareno
malware
conjunto
redu
cido
programas
benignos
ﬁnalizando
ası
elaboracion
comparaciones
conclusiones
v
indice
general
resumen
iii
introduccion
i
marco
teorico
vision
historica
riesgos
inherentes
tecnologıa
ataques
informaticos
ciberdelito
avances
inteligencia
artiﬁcial
gran
capacidad
almacenamiento
alto
poder
procesamiento
software
requerido
resumen
conceptos
seguridad
informatica
hackers
malware
tipos
malware
metodos
deteccion
analisis
estatico
analisis
dinamico
signaturebased
vs
behaviorbased
necesidad
machine
learning
resumen
data
mining
tratamiento
datos
proceso
data
mining
obtencion
datos
tipos
datos
preprocesamiento
datos
seleccion
ingenierıa
atributos
ingenierıa
atributos
datos
categoricos
normalizacion
atributos
vi
seleccion
atributos
visualizacion
datos
resumen
conceptos
machine
learning
deﬁnicion
surgimiento
machine
learning
etapas
proceso
machine
learning
conjunto
datos
tipos
estimacion
predicciones
inferencias
metodos
estimacion
f
metodo
parametrico
metodo
parametrico
balance
precision
interpretabilidad
evaluacion
precision
modelo
calidad
ajuste
quality
of
ﬁt
calidad
ajuste
clasiﬁcacion
overﬁtting
underﬁtting
balance
sesgo
varianza
clasiﬁcacion
metodos
aprendizaje
categorizacion
metodos
aprendizaje
resumen
modelos
clasiﬁcacion
logistic
regression
knearest
neighbors
naıve
bayes
support
vector
machines
decision
trees
metodos
ensamble
random
forest
xgboost
redes
neuronales
artiﬁciales
redes
neuronales
profundas
evaluacion
modelos
clasiﬁcacion
matriz
confusion
receiver
operating
characteristic
curve
resumen
vii
ii
implementacion
data
mining
generacion
dataset
conjunto
inicial
datos
archivos
asm
archivos
bytes
familias
malware
analisis
seleccion
caracterısticas
mas
relevantes
extraccion
datos
dlls
secciones
codigos
operacion
procesamiento
archivos
asm
totalizacion
ocurrencias
calculo
proporciones
determinacion
features
mas
relevantes
consolidacion
resultados
resumen
snapshots
archivos
asm
captura
snapshots
entrenamiento
red
neuronal
tamanos
archivos
compression
rate
ngramas
detalles
tecnicos
conclusion
analisis
exploratorio
preprocesamiento
datos
estructura
contenido
dataset
valores
nulos
datos
faltantes
analisis
valores
nulos
resolucion
valores
nulos
distribucion
valores
importancia
variables
seleccion
variables
estandarizacion
atributos
correlacion
extraccion
atributos
kernel
pca
resumen
clasiﬁcacion
malware
algoritmos
clasiﬁcacion
knearest
neighbors
implementacion
metricas
evaluacion
random
forest
implementacion
viii
metricas
evaluacion
xgboost
implementacion
metricas
evaluacion
artiﬁcial
neural
networks
implementacion
metricas
evaluacion
comparaciones
conclusiones
deteccion
malware
obtencion
desensamblado
archivos
benignos
generacion
nuevo
dataset
analisis
exploratorio
preprocesamiento
implementacion
solucion
modelo
base
tratamiento
sobreajuste
overﬁtting
complejidad
modelo
tasa
aprendizaje
learning
rate
parada
temprana
early
stop
regularizacion
pesos
weight
regularization
agregado
dropout
resultados
obtenidos
xgboost
solucion
alternativa
modelado
resultados
obtenidos
comparaciones
conclusiones
conclusiones
trabajos
futuros
bibliografıa
ix
indice
ﬁguras
estadıstica
total
ataques
malware
vs
potencially
unwanted
application
pua
almacenamiento
vision
historica
medio
almacenamiento
comparativa
ley
moore
proceso
data
mining
sesgo
varianza
conjunto
datos
etiquetado
a
nearest
neighbor
nn
b
nearest
neighbor
nn
maximizacion
margen
constitucion
arboles
decicion
random
forest
como
particiona
conjunto
entrenamiento
evolucion
xgboost
decision
trees
representacion
visual
red
neuronal
simple
extracto
archivo
aguvpoccafmyvdyfgbasm
extracto
archivo
anoozdnbpxirmrbscjbytes
procesamiento
archivos
asm
extraccion
dlls
archivos
asm
extraccion
codigos
seccion
archivos
asm
extraccion
codigos
operacion
archivos
asm
calculo
totalizacion
ocurrencias
determinacion
features
mas
importante
cada
familia
top
dlls
mas
relevantes
cada
clase
malware
top
codigos
operacion
mas
relevantes
cada
clase
malware
top
codigos
seccion
mas
relevantes
cada
clase
malware
obtencion
proporciones
ocurrencias
relevantes
archivo
obtencion
proporciones
ocurrencias
relevantes
archivo
dlls
codigos
operacion
seccion
snapshots
x
bytes
cada
familia
malware
x
kfold
utilizado
clasiﬁcar
snapshots
muestra
resultados
red
neuronal
clasiﬁcar
snapshots
extraccion
tamanos
archivos
tamano
archivos
compri
midos
proceso
extraccion
ngramas
top
gramas
mas
relevantes
cada
clase
malware
top
gramas
mas
relevantes
cada
clase
malware
top
gramas
mas
relevantes
cada
clase
malware
extraccion
features
archivos
asm
kde
plot
header
kde
plot
ngrama
proc
mov
push
mov
kde
plot
ngrama
add
pop
kde
plot
seccion
seg
importancia
variables
correlacion
pearson
analisis
componentes
kernel
pca
matriz
confusion
k
nearest
neighbors
roc
k
nearest
neighbors
matriz
confusion
random
forest
roc
random
forest
matriz
confusion
xgboost
roc
xgboost
precision
accuracy
modelo
clasiﬁcacion
familias
perdida
loss
modelo
clasiﬁcacion
familias
matriz
confusion
artiﬁcial
neural
networks
roc
artiﬁcial
neural
networks
correlacion
pearson
clasiﬁcacion
malwareno
malware
importancia
variables
clasiﬁcacion
malwareno
malware
analisis
componentes
kernel
pca
clasiﬁcacion
malwa
reno
malware
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
perdida
loss
modelo
clasiﬁcacion
malwareno
malware
conﬁguracion
hiper
parametros
clasiﬁcacion
malwareno
malware
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
perdida
accuracy
modelo
clasiﬁcacion
malwareno
malware
matriz
consuﬁcon
modelo
clasiﬁcacion
malwareno
malware
roc
modelo
clasiﬁcacion
malwareno
malware
xi
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
utilizando
xgboost
error
modelo
clasiﬁcacion
malwareno
malware
utilizando
xgboost
matriz
confusion
clasiﬁcacion
malwareno
malware
utilizando
xgboost
roc
clasiﬁcacion
malwareno
malware
utilizando
xgboost
capitulo
introduccion
vivimos
tecnologıa
cumple
rol
importante
vidas
personas
utilizan
internet
tipo
actividades
tareas
sensibles
pagar
cuentas
realizar
compras
consultar
ban
carios
mantener
contacto
amistades
familiares
ver
pelıculas
leer
noticias
frecuentemente
lleva
instalar
distintas
aplicaciones
dispositivos
aceptar
terminos
condiciones
sitios
companıas
saber
realmente
que
datos
acceso
que
estos
seran
usados
mismo
modo
inadvertidamente
no
diariamente
transmitimos
informacion
sensi
ble
contrasenas
datos
tarjetas
credito
canales
conﬁamos
seguros
nadie
esta
escuchando
forma
similar
compartimos
informa
cion
personal
ubicacion
fotos
redes
sociales
raramente
deteniendonos
pensar
que
lado
puede
haber
alguien
malintencionado
creando
perﬁl
actividades
numero
aplicaciones
utilidades
internet
es
lugar
dudas
ex
tenso
base
misma
software
software
dispositivos
servidores
equipos
intermedios
conectan
software
cual
mencionado
conﬁamos
diariamente
embargo
este
toda
construccion
humana
susceptible
errores
vulnerabilidades
escenarios
previstos
mas
aun
errores
vulnerabilidades
vez
detectados
llevan
tiempo
corregir
y
casos
depende
companıas
usuarios
sistemas
aplicar
actualizaciones
solucionan
problemas
contexto
hackers
personas
malintencionadas
aprovechan
vulnerabilidades
software
yo
conﬁanza
personas
despliegan
co
nocimientos
herramientas
llevar
cabo
objetivos
quizas
mas
comun
herramientas
malware
termino
malware
malicious
software
programa
cuyo
ﬁn
comprometer
cualquier
computadora
dispositivo
inteligen
te
disenado
hacker
ﬁnes
maliciosos
robar
informacion
conﬁ
dencial
penetrar
redes
danar
infraestructuras
crıticas
etc
programas
pueden
capitulo
introduccion
incluir
virus
worms
troyanos
spyware
bots
rootkits
ransomware
otros
segun
prestigioso
instituto
dedicado
seguridad
it
avtest
cada
dıa
producen
mas
nuevos
programas
maliciosos
malware
potentially
unwanted
applications
pua
incremento
ultimos
anos
cercano
representa
perdidas
millonarias
companıas
gobiernos
sitio
cyber
security
ventures
estima
perdida
anual
danos
relacionados
cibercrimen
alcanzarıa
mil
millones
dolares
nivel
global
datos
realmente
alarmantes
representaran
desafıo
humanidad
debera
enfrentar
proximas
decadas
empresas
dedicadas
desarrollo
antivirus
tales
norton
avg
mcafee
kaspersky
otros
hacen
mejor
esfuerzo
hacer
frente
problemati
ca
tradicionalmente
programas
utilizaban
metodo
signaturebased
deteccion
malware
signature
secuencia
corta
bytes
sirve
identiﬁcar
malwares
conocidos
embargo
metodo
capaz
proveer
forma
identiﬁcar
ataques
zeroday
malwares
polimorﬁcos
utilizando
tecni
cas
ofuscacion
capaces
crear
cientos
variedades
mismo
dado
cuentan
registros
mismos
ultimos
anos
grupos
investigadores
junto
comunidad
antimalware
reportado
utilizando
tecnicas
machine
learning
deep
learning
analisis
deteccion
malware
existen
dos
tecnicas
pueden
aplicar
decidir
codigo
programa
benigno
maligno
sea
rea
lizando
analisis
estatico
dinamico
tecnicas
analisis
estatico
eje
cutan
codigo
sino
solo
examinan
estructura
propiedades
datos
binarios
tencicas
analisis
dinamico
cambio
ejecutan
codigo
observar
comportamiento
ejecucion
red
ambientes
con
trolados
ejemplo
sandbox
sistemas
deteccion
malwares
utilizan
analisis
estatico
dinamico
incluso
ambos
proposito
investigacion
objetivo
central
evaluar
efectivi
dad
utilizar
distintas
tecnicas
analisis
estatico
relacionadas
machine
lear
ning
data
mining
deteccion
clasiﬁcacion
malware
aplicar
tecnicas
deteccion
temprana
malware
puede
resultar
particular
utilidad
identiﬁcar
ataques
zeroday
zeroday
malware
desconocido
decir
nue
vo
tipo
codigo
malicioso
aun
creado
parches
revisiones
resuelvan
falla
seguridad
proceso
clasiﬁcacion
deteccion
sera
llevado
cabo
trabajo
cons
tara
diversas
etapas
comenzando
obtencion
datos
estos
seran
httpswwwavtestorgenstatisticsmalware
httpscybersecurityventurescomcybercrimedamagestrillionby
capitulo
introduccion
componen
conjunto
partida
estaran
conformados
casi
mues
tras
archivos
malignos
desensamblados
vez
hecho
esto
tendra
lugar
cons
truccion
dataset
partir
extraccion
caracterısticas
mas
relevantes
consideradas
mayor
interes
conjunto
datos
etapa
deno
minamos
data
mining
consideramos
quizas
mas
importantes
mas
tiempo
demandara
toda
investigacion
dataset
generado
debera
ser
sometido
distintas
tecnicas
preprocesamiento
depurado
preparacion
pueda
ser
utilizado
algoritmos
machine
learning
finalmente
realizara
construccion
ajuste
modelos
clasiﬁcacion
deteccion
con
siderados
apropiados
dicha
tarea
resultados
obtenidos
seran
analizados
comparados
empıricamente
basandonos
distintas
metricas
parte
i
marco
teorico
capitulo
vision
historica
avance
tecnologıa
ultimos
tiempos
traıdo
consigo
grandes
bene
ﬁcios
poblacion
usuarios
general
avances
campo
medicina
seguridad
intercomunicacion
personas
encuentran
fısicamente
distintos
lugares
planeta
incluso
permitido
aparicion
nuevos
mer
cados
gran
potencial
crecimiento
embargo
beneﬁcios
vienen
acompanados
riesgos
casi
manera
inherente
ademas
oportuni
dades
tambien
conlleva
amenzazas
principalmente
industria
software
amenazas
malware
incremento
exponencial
haciendolos
solo
mas
soﬁsticados
complejos
sino
tambien
mas
difıciles
detectar
siguiente
capıtulo
dara
brevemente
marco
historico
relacionado
ries
go
tecnologıa
ataques
informaticos
mientras
mas
adelante
abor
daran
avances
campo
inteligencia
artiﬁcial
ultimos
anos
riesgos
inherentes
tecnologıa
nuevas
tecnologıas
proposito
otorgar
diferentes
beneﬁcios
personas
logrado
exitosamente
embargo
tambien
existen
conse
cuencias
adversas
derivadas
progreso
segun
sitio
welivesecurity
eset
estos
riesgos
asociados
tecnologıa
inteligencia
artiﬁcial
ai
denominado
mayor
avance
tecnologicode
ultimos
anos
comenzado
mostrar
in
dicios
peligro
ejemplo
fake
news
noticias
falsas
deep
fakes
imagenes
persona
alterada
digitalmente
ası
ca
racterısticas
aun
vislumbrado
completo
interfaces
computadoracerebro
hıperautomatizacion
quiere
decir
combina
cion
robotica
inteligencia
articial
httpswwwwelivesecuritycomlaesciberataquesprincipalesamenazas
httpswwwesetcom
capitulo
vision
historica
tecnologıa
movil
quinta
generacion
g
nuevas
tecnologıas
depen
den
infraestructuras
alta
velocidad
embargo
dadas
condiciones
actuales
pronostican
deﬁcits
signiﬁcativos
capacidad
cobertura
inversiones
redes
telecomunicaciones
desafıo
estara
cons
truir
infraestructura
moderna
ademas
introducir
sistemas
seguros
conﬁables
dentro
capacidades
existentes
computacion
cuantica
computacion
cuantica
podrıa
reducir
drasticamen
tiempo
necesario
resolver
problemas
matematicos
actual
mente
apoyan
tecnicas
cifrado
importante
cuenta
capacidad
procesamiento
podrıa
volver
impracticos
algoritmos
criptograﬁcos
actualidad
correrıa
riego
inutilizar
mayorıa
sistemas
actuales
infraestructura
crıtica
seguridad
datos
computacion
nube
computacion
nube
potencial
desarrollar
distintos
sectores
expandir
acceso
tecnologico
areas
remotas
ası
vincularse
tecnologıas
mismo
tiempo
mayor
cantidad
datos
alojados
nube
empresas
estan
acumulando
cada
vez
mas
informacion
personal
crea
potenciales
riesgos
privacidad
seguridad
datos
ademas
riesgos
asociados
tecnologıa
tambien
destacan
aspectos
re
lacionados
ciberseguridad
ataques
ciberneticos
adoptan
multiples
formas
estan
extendiendo
incluso
ambiente
fısico
sentido
cibera
taques
infraestructuras
crıticas
comienzan
aparecer
normalidad
industrias
energetica
salud
transporte
afectando
incluso
ciudades
enteras
mientras
tecnologıa
campo
encuentran
permanente
crecimiento
tambien
cibercrimen
ataques
perpetrados
grupos
cada
vez
mas
or
ganizados
cuentan
gran
disponibilidad
herramientas
creadas
tales
ﬁnes
probabilidad
baja
ser
detectados
enjui
ciados
ataques
informaticos
ciberdelito
ultima
decada
mostrado
tener
importante
incremento
ataques
in
formaticos
razon
tal
crecimiento
debe
cambio
motivacion
detras
ataques
hace
anos
principal
objetivo
ver
que
tan
lejos
podıa
llegar
embargo
dejado
ser
caso
actualidad
ataques
esconden
gran
gama
intereses
redito
economico
mas
preponde
rante
incluso
empezado
realizar
ataques
ﬁn
robar
informacion
yo
desestabilizarlos
ataques
informaticos
ciberdelito
siguiente
graﬁco
permite
observar
claramente
aumento
numero
ata
ques
registran
cada
ano
correspondientes
ultima
decada
figura
estadıstica
total
ataques
avtest
institutos
mas
reconocidos
dedican
testeo
produc
tos
seguridad
it
registra
infecciones
dıa
malware
tipo
ataque
conocido
mas
comun
graﬁco
encuentra
continuacion
muestra
estadıstica
ultimo
ano
correspondiente
dos
principales
tipos
ataques
capitulo
vision
historica
figura
malware
vs
potencially
unwanted
application
pua
ciberataques
solo
impactan
industria
software
sino
tambien
economıa
empresas
gobiernos
deben
responder
dichos
ataques
avances
inteligencia
artiﬁcial
termino
inteligencia
artiﬁcial
acunado
mas
anos
despues
avances
campo
sorprendentes
hace
pocos
anos
inteligencia
artiﬁcial
parecıa
asunto
futurista
difıcilmente
podrıa
alternarnos
dıa
dıa
corto
plazo
embargo
hoy
realidad
aspira
revolucionar
varios
aspectos
sociedad
proximos
anos
avances
inteligencia
artiﬁcial
hora
superar
capacidad
humana
actividades
ajedrez
juego
go
traduccion
llegan
ahora
titu
lares
inteligencia
artiﬁcial
esta
presente
industria
desde
menos
decada
razon
recien
ahora
empiezan
verse
aplicaciones
utilizarlos
requieren
tres
cosas
alto
poder
calculo
gran
capacidad
almacenamiento
software
apropiado
ası
mismo
tecnologıas
tenıan
tener
costo
aceptable
gran
capacidad
almacenamiento
pilares
mas
importante
data
science
capacidad
almacenar
grandes
volumenes
informacion
ser
guardada
manera
con
ﬁable
transferida
grandes
velocidades
avances
inteligencia
artiﬁcial
figura
almacenamiento
vision
historica
imagen
anterior
puede
ver
izquierda
unidad
almacenado
mega
bytes
cargada
avion
unidades
alquiladas
dolares
mes
si
ajusta
precio
inﬂacion
casi
anos
despues
mega
bytes
el
doble
capacidad
vendıa
dolares
actualidad
apenas
anos
despues
valor
puede
acceder
disco
rıgido
provee
veces
almacenado
embargo
ciencia
esta
explorando
nuevas
direcciones
prometiendo
revolucionar
modo
almacenamos
informacion
utilizacion
adn
dispositivos
solo
minimizado
drasticamente
tamano
sino
tambien
aumentado
capacidad
almacenamiento
exponencialmente
siguiente
cuadro
presenta
comparativa
discos
rıgidos
memorias
ﬂash
utiliza
cion
adn
capitulo
vision
historica
figura
medio
almacenamiento
comparativa
alto
poder
procesamiento
poder
procesar
grandes
volumenes
datos
actualidad
necesita
gran
poder
computo
poder
procesar
ley
moore
sigue
observando
fecha
permite
poner
perspectiva
aumento
poder
calculo
permite
ver
como
hace
pocos
anos
computadoras
lejos
lograr
capacidad
computacional
poseen
actualmente
figura
ley
moore
la
ley
moore
establece
basicamente
capacidad
computo
duplica
cada
dieciocho
meses
resumen
software
requerido
concepto
computadora
inteligente
surgio
prueba
alan
turing
planteo
entonces
siguientes
quince
veinte
anos
tuvie
ron
lugar
esfuerzos
campo
tales
primeros
robots
compu
tadoras
mark
i
perceptron
capaz
aprender
nuevas
habilidades
ensayo
error
embargo
ningun
avance
substancial
deep
blue
derroto
campeon
ajedrecista
garry
kasparov
partir
anos
actualidad
machine
learning
inteligencia
artiﬁcial
areas
relacionadas
empezado
crecer
cada
vez
mas
adoptarse
tipo
cam
pos
reﬂexionar
acerca
causas
detras
demora
explosion
disciplinas
mencionado
carencias
materia
procesamiento
alma
cenamiento
tambien
destacar
falta
lenguajes
programacion
acordes
sistemas
bases
datos
procesamiento
paralelo
distribuido
herramientas
resumen
presente
capıtulo
menciono
como
avances
tecnologicos
impactan
vida
personas
riesgos
inherentes
estos
traen
consigo
tambien
abordo
tema
ataques
informaticos
cibercrimen
actualidad
como
estos
ido
incrementando
evolucionado
manera
alarmante
ultimo
estudio
avance
inteligencia
artiﬁcial
ultimos
anos
cuales
pilares
explicarıan
que
uso
venido
popularizado
ultimos
anos
proximo
capıtulo
veran
conceptos
relacionados
seguridad
in
formatica
distintas
motivaciones
personas
cometen
ataques
in
formaticos
cuales
metodos
pueden
ser
utilizados
detectar
ataques
el
test
turing
estipula
persona
interactuando
maquina
puede
darse
cuenta
esta
persona
entonces
constituye
evidencia
maquina
considerada
inteligente
capitulo
conceptos
seguridad
informatica
habla
seguridad
informatica
reﬁere
practica
preservar
defender
aquel
software
computadoras
servidores
dispositivos
moviles
siste
electronicos
redes
bases
datos
ataques
maliciosos
ello
impor
tante
conocer
solo
conceptos
relacionados
dicho
tema
sino
tambien
cuales
procesos
protocolos
metodos
herramientas
pueden
utilizar
hacer
frente
dicha
amenaza
siguiente
capıtulo
describiran
ciertos
conceptos
fundamentales
relaciona
dos
seguridad
informatica
comenzara
describiendo
como
pueden
clasiﬁcar
diferentes
tipos
hackers
descripcion
distintas
clases
malware
pueden
encontrarse
ﬁnalmente
cuales
metodos
detectar
programas
hackers
utiliza
termino
ingles
hacker
referirse
aquella
persona
experta
computadoras
habilidades
conocimientos
tecnicos
especıﬁcos
resolver
problema
mismos
pueden
ser
clasiﬁcados
siguientes
categorıas
white
hat
hackers
expertos
seguridad
utilizan
distintas
tecnicas
co
mo
penetration
testing
evaluar
tan
segura
informacion
organizacion
back
hat
hackers
categorıa
mas
generica
referirse
hackers
general
grupo
encuentran
aquellos
crean
virus
inﬁltran
redes
etc
script
kiddies
termino
derogatorio
usa
referirse
aque
llos
hackers
pocos
conocimientos
simplemente
utilizan
herramientas
creadas
alguien
mas
capitulo
conceptos
seguridad
informatica
hacktivists
atacantes
motivados
razones
polıticas
yo
tambien
religiosas
desean
exponer
personas
actividades
ilıcitas
hackers
patrocinados
estados
hackers
contratados
gobiernos
po
nen
disposicion
recursos
ilimitados
atacar
u
organiza
ciones
hackers
espıas
contratados
empresas
objetivo
inﬁltrar
com
petencia
robar
informacion
ciberterroristas
hackers
que
motivados
creencias
polıticas
religiosas
intentan
crear
miedo
caos
sociedad
atacando
infraestructuras
claves
lado
proliferado
comunidades
hackers
comparten
conocimiento
y
ademas
distribuyen
herramientas
forma
gratuita
paga
in
cluso
suelen
encontrarse
publicaciones
ofrece
dinero
cambio
des
cubrimiento
nuevas
vulnerabilidades
determinado
sistema
operativo
soft
ware
malware
palabra
malware
proviene
abreviacion
malicious
software
puede
ser
utilizado
comprometer
funciones
sistema
robo
informacion
saltear
con
troles
acceso
cualquier
forma
causar
dano
host
esta
ejecutando
tipos
malware
malwares
pueden
dividirse
distintas
categorıas
dependiendo
proposi
to
continuacion
describen
clases
adware
cuya
abreviatura
proviene
advertisingsupported
software
tipo
malware
cuyo
unico
proposito
visualizacion
publicidad
ejemplo
comun
podrıa
ser
utilizacion
ventanas
emergentes
sitios
web
aque
llos
ejecutados
software
muchas
veces
aplicaciones
ofrecen
ver
siones
gratuitaspero
estan
atestadas
publicidades
adwares
patrocinados
empresas
publicidad
utilizados
co
mo
herramienta
generar
ganancias
monetarias
bot
bots
programas
escritos
ejecutar
determinadas
operaciones
automaticamente
mientras
bots
creados
propositos
daninos
juegos
lınea
subastas
internet
concursos
lınea
etc
uti
lizacion
ﬁnes
maliciosos
incrementando
bots
pueden
ser
utilizados
botnets
conjuntos
computadoras
controladas
terceros
efectuar
ataques
ddos
distributed
denial
of
service
spambots
malware
muestran
publicidades
sitios
web
web
spiders
recopilan
informa
cion
servidores
distribucion
malware
disfrazado
resulta
dos
busquedas
sitios
descarga
bug
contexto
software
bug
falla
programa
produce
resultados
deseados
fallas
normalmente
resultado
error
hu
mano
general
encuentran
codigo
fuente
compilado
programa
ciertos
bugs
menores
simplemente
afectaran
funcionamiento
programa
pueden
llevar
tiempo
ser
detectados
embargo
bugs
mas
signiﬁcativos
pueden
producir
caıdas
sistema
mismos
dejen
funcionar
bugs
mas
peligrosos
ponen
riesgo
seguridad
sistema
pueden
ser
aprovechados
saltear
controles
autenticacion
usuarios
sobrescribir
privilegios
robar
informacion
ransomware
ransomware
esencia
forma
malware
toma
cau
tivo
sistema
computadora
afectada
solicita
recompensa
recuperacion
malware
restringira
acceso
usuario
dicha
compu
tadora
sea
encriptando
archivos
encuentran
disco
duro
bloqueando
completamente
sistema
mostrando
mensajes
intencion
forzar
usuario
pagar
creador
malware
recompensa
remo
ver
restricciones
modo
recuperar
acceso
computadora
rootkit
rootkit
tipo
software
malicioso
disenado
acceder
controlar
remotamente
computadora
ser
detectado
usuarios
programas
seguridad
vez
rootkit
instalado
atacante
podra
ejecutar
archivos
accederrobar
informacion
modiﬁcar
conﬁguracio
nes
sistema
alterar
programas
como
ejemplo
programas
seguri
dad
puedan
detectar
rootkit
instalar
programas
maliciosos
controlar
computadora
parte
botnnet
prevencion
deteccion
remo
cion
tipo
malware
suele
ser
tarea
difıcil
dada
naturaleza
sigilosa
operan
spyware
spyware
tipo
malware
cuya
funcion
espiar
actividad
usuario
conocimiento
ejemplo
captar
entradas
teclado
colectar
datos
informacion
cuentas
autenticaciones
datos
ﬁnancieros
trojan
horse
trojan
horse
tambien
conocido
troyano
tipo
malware
disfraza
sı
mismo
archivo
normal
enganar
usuarios
descargarlos
instalarlos
trojan
puede
darle
atacante
acceso
remoto
computadora
infectada
vez
ganado
acceso
este
podra
robar
datos
usuario
instalar
programas
maliciosos
modiﬁcar
archi
vos
monitorear
actividad
usuario
virus
virus
tipo
malware
capaz
copiarse
sı
mismo
es
parcirse
computadoras
adjuntandose
mismos
programas
capitulo
conceptos
seguridad
informatica
ejecutando
codigo
usuario
inicia
dichos
programas
virus
pue
den
ser
utilizados
robar
informacion
danar
computadora
aloja
yo
red
crear
botsnets
robar
dinero
mostrar
publicidad
worm
worms
computadoras
encuentran
tipos
mas
comunes
malware
esparcen
computadoras
explotando
vulnerabilida
des
sistemas
operativos
traves
red
worms
causan
dano
red
computadora
aloja
consumiendole
ancho
banda
sobrecar
gando
servidores
web
worms
computadoras
pueden
ser
clasiﬁcados
tipo
virus
poseen
varias
caracterısticas
distinguen
mayor
diferencia
worms
habilidad
auto
replicarse
esparcirse
independientemente
mientras
virus
requieren
activi
dades
humanos
esparcirse
ejecutar
programa
abrir
archivo
backdoor
backdoor
tipo
malware
provee
puerta
trasera
sistema
atacantes
sı
mismo
causa
ningun
dano
provee
atacantes
acceso
sistema
modo
este
pueda
hacer
desee
el
keylogger
idea
detras
malware
registrar
todas
teclas
presio
nadas
usuario
y
modo
almacenar
datos
provistos
incluyendo
contrasenas
numeros
tarjetas
credito
cualquier
infor
macion
sensible
remoteaccess
trojan
rat
tipo
malware
permite
atacante
ganar
acceso
remoto
sistema
realizar
cualquier
modiﬁcacion
este
desee
metodos
deteccion
todas
tecnicas
deteccion
malware
pueden
ser
divididas
dos
gran
des
categorıas
signaturebased
behaviorbased
vez
existen
dos
conceptos
fundamentales
relacionados
analisis
cuales
clasiﬁcan
en
analisis
estatico
analisis
dinamico
malware
analisis
estatico
nombre
indica
rea
lizado
estaticamente
ejecucion
archivo
mientras
que
dinamico
programa
analizado
ejecucion
ejemplo
maquina
virtual
analisis
estatico
analisis
estatico
puede
ser
visto
lectura
codigo
fuente
analiza
sintaxis
estructura
archivo
propiedades
malware
intento
inferir
determinar
existe
comportamiento
malicioso
analisis
estatico
puede
incluir
diversas
tecnicas
metodos
deteccion
escaneo
mediante
antivirus
antivirus
herramienta
puede
ser
utilizada
deteccion
software
malicioso
estos
normalmente
poseen
base
datos
secciones
codigos
sospechosos
ﬁle
signatures
co
mo
ası
tambien
analisis
concordancia
patrones
comportamientos
identiﬁcar
archivos
potencialmente
maliciosos
heuristics
hashing
metodo
comun
utiliza
identiﬁcar
unıvoca
mente
malware
traves
programa
analiza
software
malicioso
generandose
etiqueta
hash
identiﬁca
funciones
hash
mas
comunmente
utilizadas
encuentran
messagedigest
algorithm
md
secure
hash
algorithm
sha
busqueda
strings
busqueda
extraccion
strings
puede
ofrecer
infor
macion
funcionalidades
programa
actividad
sospechosa
ejemplo
malware
crea
archivo
nombre
dicho
archivo
almace
nado
string
binario
malware
resuelve
nombre
dominio
controlado
atacante
nombre
dominio
sera
almacenado
string
extraccion
strings
binario
puede
contener
referencias
nombres
archivos
urls
nombres
dominio
direcciones
ip
comandos
ataque
claves
registro
etc
bien
extraccion
sı
misma
otorga
entendimiento
completo
acerca
proposito
capacidades
archi
vo
sı
puede
ofrecer
pistas
pueden
ser
utilizadas
entender
que
capaz
malware
empaquetamiento
ofuscamiento
malware
creadores
malware
fre
cuentemente
utilizan
tecnicas
empaquetamiento
ofuscamiento
hacer
archivos
mas
difıciles
detectar
analizar
programas
ofuscados
esconder
ejecucion
malware
programas
empaqueta
dos
pertenecen
subconjunto
ofuscados
cuyo
objetivo
comprimir
programa
malicioso
modo
pueda
ser
analizado
archivo
ejecutable
formato
portable
metadatos
formatos
ar
chivo
pueden
revelar
informacion
importante
acerca
funcionalidad
programa
archivos
formato
portable
executable
pe
utilizados
sistema
operativo
microsoft
windows
r
archivos
poseen
estructura
datos
informacion
utilizada
loader
sistema
operativo
ejecucion
archivos
archivos
pe
contienen
enca
bezado
incluye
informacion
acerca
codigo
tipo
aplicacion
funciones
librerıas
requeridas
requerimientos
espacio
informacion
pueden
arrojar
encabezados
gran
valor
analisis
malware
linkeo
librerıas
funciones
forma
recopilar
informacion
acerca
ejecutable
analizando
lista
funciones
importadas
codigo
librerıas
puede
ser
linkeado
estaticamente
tiempo
ejecucion
capitulo
conceptos
seguridad
informatica
dinamicamente
realizarse
estaticamente
encabezado
archivos
pe
podrıa
verse
que
librerıas
incluidas
codigo
problema
que
general
metodo
mas
comunmente
utilizado
atacantes
linkeo
tiempo
ejecucion
dinamico
modo
librerıas
vayan
utilizarse
seran
solicitadas
programa
necesite
desensamblado
tecnica
desensamblado
disassembler
consiste
to
mar
codigo
compilado
binario
convertirlo
codigo
assembler
utilizando
ingenierıa
inversa
mismo
luego
analizado
inferir
logica
inten
ciones
tecnica
mas
comun
mas
conﬁable
analisis
estatico
analisis
estatico
menudo
llevado
cabo
ayuda
ciertas
herramien
tas
pero
mas
alla
simple
analisis
estas
pueden
proveer
informacion
tecni
cas
proteccion
utilizan
malwares
principal
ventaja
analisis
estatico
posibilidad
descubrir
posibles
escenarios
comportamiento
in
vestigar
codigo
sı
mismo
permite
analista
conocer
mayor
detalle
como
ejecuta
malware
limitarse
situacion
actual
incluso
tipo
analisis
mas
seguro
dinamico
codigo
necesita
ejecutarse
tan
to
pone
riego
sistema
ejecucion
mas
costosa
tiempo
ello
que
bien
resulta
tecnica
interesante
misma
realizada
ambien
tes
dinamicos
mundo
real
tales
antivirus
sino
mas
bien
propositos
investigacion
ejemplo
desarrollo
signatures
malware
zeroday
analisis
dinamico
diferencia
analisis
estatico
analisis
dinamico
permite
observar
verda
dero
funcionamiento
malware
porque
ejemplo
sola
existencia
action
string
binario
signiﬁca
accion
efecto
vaya
ejecutarse
analisis
dinamico
tambien
forma
eﬁciente
identiﬁcar
funcionalidad
malware
ejemplo
malware
archivo
log
keylogger
analisis
dinamico
provee
posibilidad
localizar
dicho
archivo
sistema
descubrir
que
tipo
registros
almacena
descifrar
donde
enviada
dicha
informacion
etc
tipo
analisis
interno
difıcil
realizarlo
solo
tecnicas
analisis
estatico
bien
analisis
dinamico
tecnica
extremadamente
poderosa
deberıa
ser
realizada
vez
completado
analisis
estatico
mismo
pue
poner
riesgo
red
sistema
tecnicas
dinamicas
tambien
limitaciones
caminos
posibles
pueden
llegar
ejecutarse
mien
tras
malware
esta
funcionamiento
ejemplo
caso
malware
ejecuta
lınea
comando
requiere
argumentos
cada
argumento
podrıa
ejecutar
diferentes
funcionalidades
programa
mientras
sepan
cuales
opciones
sera
posible
examinar
dinamicamente
todas
funcionalidades
puede
realizar
programa
metodos
deteccion
existen
productos
software
pueden
ser
utilizados
llevar
ca
bo
analisis
dinamico
quiza
mas
popular
uso
tecnologıas
sandbox
sanbox
mecanismo
seguridad
permite
ejecutar
programas
inseguros
ambiente
seguro
danar
integridad
sistema
real
quiere
prote
ger
sandboxes
componen
ambientes
virtualizados
menudo
ofrecen
simulacion
red
servicios
ofreciendo
modo
seguro
ejecutar
soft
ware
malware
desea
testear
signaturebased
vs
behaviorbased
metodo
analisis
signaturebased
metodo
estatico
basa
signatu
res
predeﬁnidas
pueden
ser
archivos
ﬁngerprints
ejemplo
hashes
genera
das
md
sha
strings
estaticos
archivos
metadata
otros
deteccion
malware
caso
serıa
llevado
cabo
siguiente
manera
llegada
nuevo
archivo
sistema
mismo
estaticamente
analizado
software
antivirus
existe
alguna
coincidencia
cualquiera
signatures
regis
tradas
dispara
alerta
indicando
archivo
considerado
sospechoso
muchas
veces
tipo
analisis
resultan
suﬁciente
dado
malware
detectados
basandose
valor
hash
embargo
creadores
malware
comenzado
desarrollar
programas
que
alguna
manera
capaces
cambiar
signature
caracterıstica
malwares
referida
polimorﬁsmo
tanto
dada
condicion
po
limorﬁca
pueden
ser
detectados
solamente
utilizando
tecnicas
deteccion
ba
sadas
signatures
nueva
signature
creada
situacion
llevo
empresas
desarrolladoras
antivirus
utilizar
nuevas
tecnicas
detec
cion
analisis
behaviorbased
tambien
conocido
heuristicsbased
metodo
observa
como
comporta
malware
ejecucion
buscando
senales
comportamiento
malicioso
modiﬁcaciones
archivos
host
claves
registro
establecimiento
conexiones
sospechosas
etc
sı
mismas
cada
acciones
representan
necesariamente
senales
malware
combinadas
pueden
elevar
nivel
sospecha
acerca
archivo
existe
cierto
umbral
ni
vel
sospecha
deﬁnido
cualquier
malware
exceda
nivel
dispara
alerta
nivel
precision
deteccion
malware
basado
comportamiento
behaviorbased
dependera
implementacion
mas
populares
utilizan
am
bientes
virtuales
ejemplo
sandbox
ejecutar
archivo
monitorear
comportamiento
bien
metodo
consume
mas
tiempo
mas
seguro
archivo
chequeado
ejecucion
principal
ventaja
meto
do
deteccion
basado
comportamiento
behaviorbased
que
teorıa
puede
identiﬁcar
solo
familias
malware
sino
tambien
ataques
zeroday
malware
capitulo
conceptos
seguridad
informatica
aun
identiﬁcado
virus
polimorﬁcos
embargo
cuen
ta
alto
grado
esparcimiento
malware
tales
analisis
resultan
adecuados
trata
malwares
nuevos
polimorﬁcos
necesidad
machine
learning
menciono
anteriormente
detectores
malware
basados
signatures
pueden
ser
efectivos
malware
conocido
descubier
to
alguna
herramienta
antivirus
embargo
resultan
utiles
detec
cion
aquellos
virus
polimorﬁcos
capaces
cambiar
signature
parte
precision
detectores
basados
comportamiento
behaviorbased
siem
pre
resulta
ser
adecuada
deteccion
dando
resultado
cantidades
falsos
positivos
falsos
negativos
necesidad
encontrar
nuevos
metodos
deteccion
esta
dada
alto
grado
propagacion
poseen
virus
polimorﬁcos
llevado
comenzaran
explorar
nuevas
alternativas
capaces
brindar
solucion
problema
metodos
deteccion
clasiﬁcacion
utilizando
tecnicas
data
mining
machine
learning
arrojado
buenos
resultados
campo
resumen
pudo
ver
desarrollo
capıtulo
existen
diferentes
moti
vaciones
encuentran
detras
ataques
informaticos
perpetuados
hackers
encuentran
ganancia
economica
dano
infraestructuras
satisfaccion
personal
tambien
realizo
estudio
diferentes
tipos
malware
como
pueden
clasiﬁcarse
ultimo
analizaron
cuales
tecnicas
deteccion
malware
utilizadas
hoy
dıa
que
tecnicas
basadas
machine
learning
data
mining
resultan
buena
alternativa
realizacion
dicha
tarea
capıtulo
encuentra
continuacion
tendra
objetivo
realizar
estu
dio
indicando
que
consiste
proceso
data
mining
cuales
etapas
componen
tambien
estudiaran
tecnicas
utilizadas
realizar
prepro
cesamiento
datos
capitulo
data
mining
tratamiento
datos
ultimos
anos
solo
mostrado
importante
incremento
numero
complejidad
ataques
informaticos
sino
tambien
cantidad
disponibi
lidad
datos
generados
diariamente
capacidades
distintas
disciplinas
data
mining
machine
learning
estadısticas
otras
necesitadas
abordar
desafıos
ciberseguridad
data
mining
minerıa
datos
extraccion
nombre
indica
minerıade
conocimiento
partir
gran
cantidad
datos
patrones
reglas
descubiertas
tecnicas
pueden
luego
ser
utilizadas
realizar
pre
dicciones
respecto
nuevos
datos
tecnicas
data
mining
utilizan
combi
nacion
estadısticas
matematicas
inteligencia
artiﬁcial
reconocimiento
patro
nes
modo
agrupar
extraer
comportamientos
entidades
tanto
data
mining
campo
interdisciplinario
emplea
uso
herramientas
anali
sis
modelos
estadısticos
algoritmos
matematicos
metodos
machine
learning
descubrir
patrones
validos
relaciones
gran
conjunto
datos
caracterısticas
aun
descubiertas
resulta
util
encontrar
tecnicas
procedimientos
utilizados
hackers
vulnerar
sistemas
obtener
informacion
siguiente
capıtulo
describira
que
consiste
proceso
data
mining
cuales
pasos
llevarlo
cabo
abordaran
tambien
conceptos
relacio
nadas
tratamiento
preprocesamiento
datos
ultimo
explicara
manera
breve
cuales
etapas
relacionadas
machine
learning
que
com
pone
cada
una
capitulo
data
mining
tratamiento
datos
proceso
data
mining
comenzar
proceso
data
mining
importante
determinar
que
quiere
lograr
implementandolo
conoce
entendimiento
negocioo
business
understanding
fase
consiste
investigar
objetivos
requerimientos
decidir
data
mining
puede
ser
aplicado
alcanzarlos
determinando
que
tipo
datos
deben
ser
recolectados
construir
modelo
desplegable
siguiente
fase
consiste
basicamente
entendimiento
datos
data
undertanding
conjunto
datos
inicial
analizado
estudiado
determinar
apropiado
futuro
procesamiento
calidad
datos
deﬁciente
pobre
quiza
necesario
recolectar
nuevos
datos
basado
algun
criterio
mas
riguroso
siguientes
tres
etapas
son
preparacion
datos
modelado
eva
luacion
fase
preparacion
involucra
tareas
preprocesamiento
datos
crudos
que
partir
estos
algoritmos
machine
learning
puedan
pro
ducir
modelo
etapa
preprocesamiento
puede
incluir
actividades
re
quieran
construccion
modelos
muchas
herramientas
preprocesado
construyen
modelos
internos
datos
transformarlos
hecho
prepa
racion
datos
modelado
etapas
van
mano
muchas
veces
requiere
iterar
ellas
resultados
obtenidos
modelado
sue
len
dar
nueva
perspectiva
puede
afectar
tecnicas
preprocesamiento
elegidas
ultima
fase
quiza
mas
importante
depende
exito
modelo
etapa
evaluacion
etapa
evaluacion
determina
modelo
pobre
sera
necesario
reconsiderar
proyecto
entero
regresar
fase
entendimiento
negocio
para
identiﬁcar
objetivos
mas
fructıferos
recoleccion
datos
cambio
precision
modelo
suﬁcientemente
alta
entonces
siguiente
paso
sera
realizar
despliegue
normalmente
puede
signiﬁcar
integracion
sistema
mayor
funcionar
sistema
mismo
obtencion
datos
figura
proceso
data
mining
obtencion
datos
comenzar
proceso
data
mining
sera
necesario
obtener
datos
deberan
ser
recolectados
extraıdos
mundo
real
dado
dichos
datos
podran
ser
obtenidos
diferentes
fuentes
posible
posean
distintos
formatos
formatos
datos
mas
conocidos
forma
mas
comun
recolectarlos
son
csv
archivos
csv
comma
separated
values
formato
datos
mas
comunmente
utilizado
tambien
formatos
mas
antiguos
todavıa
preferidos
diferentes
sistemas
tipo
archivos
puede
contener
diferentes
tipos
datos
separados
coma
pueden
contener
encabezados
variante
csv
tsv
delimitador
lugar
ser
coma
espacio
tabular
jsonla
java
script
object
notation
json
surgio
alternativa
archivos
xml
formato
texto
totalmente
independiente
lengua
je
ciertas
convenciones
establecidas
archivoobjeto
json
simple
mente
coleccion
pares
clavevalor
tal
estructura
pares
correspondiente
representacion
mayorıa
lenguajes
diccio
narios
capitulo
data
mining
tratamiento
datos
xml
xml
extensible
markup
language
lenguaje
marcas
deﬁne
reglas
codiﬁcar
datosdocumentos
igual
json
legi
bles
humanos
independiente
plataforma
simple
usar
web
scraping
tecnica
utiliza
detectar
extraer
informacion
web
principalmente
paginas
web
proceso
web
scraping
puede
ser
realizado
manualmente
copiando
datos
utilizando
tecnicas
automati
cas
recorrer
extraer
informacion
paginas
informacion
puede
ser
luego
utilizada
herramientas
analisis
almacenada
proceso
web
scraping
puede
resumir
siguiente
manera
robot
crawler
so
licita
servidores
web
conjunto
direcciones
predeterminadas
analiza
identiﬁca
enlaces
externos
esta
pueda
contener
anade
lista
direcciones
visitar
repitiendo
proceso
posible
vez
obtenidas
paginas
realiza
extraccion
informacion
tarea
scraping
consiste
utilizar
tecnicas
expresiones
regulares
extraccion
basada
xpath
etiquetas
especıﬁcas
otras
acotar
busqueda
informacion
requerida
pagina
sql
bases
datos
datan
anos
utilizan
representar
grandes
volumenes
informacion
almacenados
forma
relacional
da
tos
encuentran
disponibles
tablas
alguna
forma
estructura
datos
bien
existen
diferentes
formas
trabajar
bases
datos
quizas
mas
comun
dentro
campo
realizando
consultas
sql
directamente
tipos
datos
seccion
previa
describio
distintos
formatos
formas
extraer
infor
macion
ellos
cada
formatos
permiten
representar
datos
distintos
tipos
tipos
datos
forma
original
forman
features
entrada
utilizaran
algoritmos
machine
learning
continuacion
explicaran
tipos
mas
importantes
datos
puede
llegar
trabajar
numerico
mas
simple
tipos
datos
disponible
datos
numeri
cos
representan
informacion
escalar
acerca
entidades
estan
ob
servadas
ejemplo
numero
visitas
pagina
web
precio
producto
peso
persona
etc
manipulacion
datos
numericos
utilizan
tecnicas
tales
normalizacion
discretizacion
bin
ning
trata
convertir
valor
numerico
valor
nominal
ordena
do
cuantiﬁcacion
otras
transformacion
datos
numericos
acuerdo
requerimientos
texto
tipo
dato
compuesto
contenido
alfanumerico
desestruc
turado
mas
comunes
datos
textuales
representan
contenido
lenguaje
humano
contienen
estructuras
gramaticales
implıcitas
preprocesamiento
datos
signiﬁcado
tipo
dato
requiere
esfuerzo
adicional
transfor
marlo
entenderlo
categorico
tipo
dato
encuentra
situado
tipo
dato
numeri
co
tipo
texto
variables
tipo
categoricas
estan
asociadas
categorıas
entidades
estan
trabajando
ejemplo
tipo
cabe
llo
persona
puede
ser
negro
castano
rubio
pelirrojo
situacion
economica
clase
baja
media
alta
valores
pueden
ser
represen
tados
numericos
alfanumericos
segun
considere
acuerdo
caracterısticas
variables
categoricas
pueden
ser
nominal
deﬁnen
unicamente
categorıa
datos
tener
cuenta
ningun
tipo
orden
ejemplo
color
cabello
negro
castano
rubio
pelirrojo
categorıas
poseen
ningun
tipo
orden
especıﬁco
ordinal
deﬁne
categorıas
tambien
establece
orden
segun
reglas
contexto
ejemplo
gente
categorizada
situacion
economica
bajo
medio
alto
pueden
ser
consideradas
orden
importante
destacar
operaciones
matematicas
estandar
suma
resta
multiplicacion
division
signiﬁcado
variables
ca
tegoricas
aunque
sintacticamente
viable
hacerlo
como
caso
variables
categoricas
numericas
preprocesamiento
datos
vez
obtenidos
datos
procedera
limpieza
transformacion
dentro
tareas
involucra
etapa
encuentran
filtrado
datos
limpieza
dataset
involucra
tareas
remocion
mani
pulacion
datos
erroneos
faltantes
imprecisos
valores
atıpicos
outlier
etc
tambien
requiere
tareas
estandarizacion
nombres
atributos
hacerlo
mas
intuitivo
legible
casteo
tipos
casteo
tipos
conversion
tipos
apropiado
da
tos
partes
mas
importantes
etapa
menudo
datos
convertidos
tipos
datos
incorrectos
extraıdos
fuente
original
diferentes
sistemas
plataformas
manejan
tipos
datos
ma
nera
distinta
darles
datos
tipo
correcto
tarea
importante
transformacion
adaptacion
estructuras
datos
muchas
veces
es
tructuras
datos
creadas
contener
dataset
ser
modiﬁcadas
objetivo
facilitar
mas
pasos
intermedios
procesamiento
capitulo
data
mining
tratamiento
datos
modelo
nuevas
columnas
incluso
nuevas
estructuras
transitorias
pueden
ser
creadas
facilitar
calculos
auxiliares
identiﬁcar
determinadas
observa
ciones
casos
necesita
cruzar
dos
mas
estructuras
datos
dispone
medios
obvios
hacerlos
como
podrıa
ser
identiﬁcador
manejo
valores
faltantes
nulos
valores
faltantes
pueden
acarrear
di
versos
problemas
ser
interpretados
incorrectamente
algoritmos
errores
calculos
yo
resultados
ﬁnales
metodo
comun
rellenar
valores
faltantes
utilizacion
calculo
media
eliminacion
duplicados
bien
cierto
cuantos
mas
datos
dis
pongan
mejor
tambien
debe
tener
presente
datos
duplicados
dataset
agregan
ningun
valor
adicional
deberıan
ser
eliminados
manipulacion
datos
categoricos
atributos
tipo
categorico
reﬁe
ren
aquellos
datos
alfanumericos
pueden
tomar
numero
limitado
valores
ejemplo
dataset
contiene
columna
genero
cuyos
va
lores
f
femenino
m
masculino
datos
solo
pueden
tomar
dos
valores
considerados
categoricos
normalizacion
valores
proceso
normalizacion
consiste
escalado
valores
atributos
proceso
normalizacion
tambien
conoce
feature
scaling
manipulacion
strings
quiere
procesar
lenguaje
na
tural
este
consta
propias
etapas
componen
proceso
tokenization
divide
string
unidades
componen
ejem
plo
dividir
sentencia
palabras
palabras
caracteres
stemming
lemmatizationconsiste
normalizar
palabras
ob
tener
raız
forma
canonica
mientras
stemming
proceso
heurıstico
lograr
forma
canonica
lemmatization
utiliza
reglas
gramaticales
vocabulario
llegar
raız
remocion
stopwordlos
textos
contienen
ciertas
palabras
apare
cen
alta
frecuencia
agregan
mucha
informacion
signos
puntuacion
conjunciones
etc
palabrasfrases
removidas
reducir
dimension
complejidad
datos
seleccion
ingenierıa
atributos
vez
datos
limpiados
transformados
seleccionaran
aque
llas
propiedades
consideradas
relevantes
formar
conoce
atributo
feature
seran
representados
dentro
conjunto
datos
columnas
atributos
pueden
ser
dos
tipos
inherentes
aquellos
seleccion
ingenierıa
atributos
obtienen
directamente
dataset
tener
realizar
ningun
tipo
calculo
ingenierıa
derivados
aquellos
obtienen
partir
atributos
existentes
ejemplo
partir
fecha
nacimiento
persona
puede
obtener
edad
ingenierıa
atributos
datos
categoricos
atributos
features
categoricos
representan
conjunto
ﬁnito
valores
dis
tintos
valores
pueden
ser
tipo
texto
numerico
cuales
vez
pueden
pertenecer
variables
categoricas
nominales
ordinales
dentro
atributos
ca
tegoricos
nominales
existe
concepto
orden
mientras
ordinales
sı
valores
alfanumericos
necesario
transformar
atributos
valores
numericos
dado
modelo
matematico
puede
trabajar
va
lores
alfanumericos
transformacion
puede
realizar
utilizando
esquema
denominado
dummy
variable
variables
tontas
cual
m
valores
categorıa
crearan
m
columnas
cuales
completaran
valor
segun
corresponda
excepto
trate
categorıa
representada
completaran
ceros
todas
demas
normalizacion
atributos
muchas
veces
necesario
trabajar
valores
numericos
diferen
tes
sı
utilizan
datos
entrada
modelo
valores
tal
estan
pueden
resultar
modelos
sesgados
cuyas
magnitudes
demasiado
al
tas
tecnicas
utilizan
realizar
normalizacion
son
escalado
estandar
intenta
estandarizar
cada
valor
columna
contiene
atributo
eliminando
valor
medio
escalando
varianza
cada
valores
proceso
tambien
conoce
centrado
escalado
puede
ser
denotado
matematicamente
como
ssxi
xi
µx
σx
donde
cada
valor
atributo
x
resta
media
µx
resultado
dividido
desviacion
estandar
σx
escalado
minmax
transforma
escala
cada
valor
atributo
tal
dicho
valor
este
dentro
rango
terminos
matematicos
serıa
mmsxi
xi
minx
maxx
minx
capitulo
data
mining
tratamiento
datos
donde
escala
cada
valor
atributo
x
sustrayendole
valor
mınimo
x
dividiendo
resultado
diferencia
valores
maximo
mınimo
atributo
escalado
robusto
gran
desventaja
escala
minmax
muchas
veces
presencia
outliers
valores
atıpicos
afectan
escala
cualquier
valor
atributo
escala
robusta
utiliza
medidas
estadısticas
escalar
atributos
verse
afectado
outliers
matematicamente
escala
puede
representar
como
rsxi
xi
mediax
iqrx
donde
escala
cada
valor
atributo
x
sustrayendole
media
x
dividiendo
resultado
iqr
interquartile
range
x
cual
serıa
rango
diferencia
primer
cuartil
tercer
cuartil
seleccion
atributos
muchas
veces
resulta
conveniente
trabajar
datasets
cuentan
quiza
cientos
atributos
grandes
conjuntos
atributos
conducen
modelos
complejos
difıciles
interpretar
posiblemente
overﬁtting
tanto
objetivo
selec
cionar
numero
optimo
atributos
representativos
problema
quiere
abordar
modo
evitar
diﬁcultades
mencionadas
estrategias
seleccion
atributos
pueden
ser
divididas
tres
grandes
areas
metodos
ﬁltrado
tecnicas
seleccionan
atributos
basandose
puramen
metricas
correlacion
informacion
mutua
etc
metodos
dependen
resultados
obtenidos
ningun
modelo
normalmente
bus
can
relacion
cada
variable
variable
quiere
predecir
mas
populares
encuentran
thresholdbased
method
metodos
basados
umbral
tests
estadısticos
metodos
envoltorio
estudia
interaccion
multiples
atributos
y
mediante
eliminaciones
recursivas
intenta
obtener
subconjunto
atributos
den
resultado
modelo
mas
eﬁciente
metodos
seleccion
hacia
atras
seleccion
hacia
adelante
mas
populares
categorıa
metodos
embebidos
tecnicas
combinan
beneﬁcios
dos
metodos
asignandoles
puntaje
score
cada
atributo
basado
impor
tancia
arboles
decision
random
forests
mas
populares
dentro
categorıa
visualizacion
datos
tecnicas
mas
representativas
seleccion
atributos
encuen
tran
thresholdbased
method
estrategia
seleccion
atributos
permite
es
tablecer
umbral
limitar
cantidad
atributos
posee
modelo
umbrales
pueden
ser
utilizados
diferentes
formas
ejemplo
esta
blecer
mınimo
yo
maximo
incluso
posible
utilizar
varianza
modo
aquellos
atributos
cuya
varianza
baja
removidos
metodos
estadısticos
consiste
seleccion
atributos
basados
utili
zacion
tests
estadısticos
existen
varios
test
estadısticos
pueden
ser
usa
dos
regresion
clasiﬁcacion
incluyen
informacion
mutua
anova
analisis
varianza
tests
chisquare
basados
puntajes
obtenidos
tests
posible
seleccionar
atributos
arrojen
mejores
resulta
dos
eliminacion
recursiva
atributos
recursive
feature
elimination
tambien
conocida
rfe
tecnica
seleccion
atributos
basados
en
voltorios
permite
ayuda
modelo
estimacion
machine
learning
rankear
asignar
puntajes
atributos
luego
eliminar
recursi
vamente
aquellos
menor
llegue
numero
especıﬁ
co
preestablecido
seleccion
basada
modelo
modelos
basados
arboles
de
cision
modelos
ensamble
random
forest
o
arboles
ensamble
pue
den
ser
utilizados
solo
modelar
sino
tambien
seleccion
atri
butos
modelos
pueden
establecer
importancia
atributos
mien
tras
construidos
seleccionando
aquellos
posean
mejor
puntuacion
descartando
aquellos
puntuacion
irrelevante
extraccion
atributos
principal
component
analysis
pca
meto
do
estadıstico
utiliza
procesos
algebra
lineal
transformar
con
junto
atributos
alta
dimensionalidad
menor
dimensionalidad
mınimo
perdida
informacion
visualizacion
datos
finalmente
lugar
visualizacion
datos
este
punto
impor
tante
utilizacion
ayudas
visuales
graﬁcos
imagenes
mapas
constituyen
herramienta
valor
exploracion
validacion
datos
disponibles
ası
tambien
deteccion
correccion
temprana
errores
que
manera
podrıan
propagarse
modelos
machine
lear
ning
generando
resultados
inesperados
errores
difıciles
identiﬁcar
corregir
capitulo
data
mining
tratamiento
datos
resumen
data
mining
minerıa
datos
proceso
identiﬁcacion
informacion
relevante
extraıda
mayorıa
veces
grandes
volumenes
datos
objetivo
descubrir
patrones
tendencias
estructurando
informacion
obtenida
modo
comprensible
posterior
utilizacion
proceso
iterativo
culminara
informacion
obtenida
satisfaga
expectativas
conocimiento
esperadas
ser
ası
proceso
repetira
uti
lizando
nuevas
variables
adoptando
tecnicas
distintas
usadas
procesos
anteriores
obtener
modelo
datos
deseado
capıtulo
encuentra
continuacion
enunciara
conceptos
machine
lear
ning
comenzando
deﬁnicion
luego
abordar
caracterısticas
mas
especıﬁ
cos
relacionados
dicho
tema
capitulo
conceptos
machine
learning
acuerdo
deﬁnicion
clasica
dada
pionero
intenligencia
artiﬁcial
arthur
lee
samuel
machine
learning
conjunto
metodos
da
compu
tadoras
la
habilidad
aprender
ser
programadas
explıcitamente
palabras
algoritmo
machine
learning
descubre
generaliza
ca
racterısticas
subyacentes
datos
observa
conocimiento
algorit
mo
puede
inferirlas
propiedades
aquellas
muestras
aun
visto
todas
caracterısticas
obtenidas
datos
formalizados
matematicamente
conoce
modelo
deteccion
malware
muestras
vistas
estarıan
repre
sentadas
archivos
asm
bytes
cuales
podrıan
ser
benignos
malignos
zero
day
malware
siguiente
capıtulo
expondran
conceptos
relacionados
machine
learning
comenzando
deﬁnicion
etapas
componen
como
funciona
miento
terminos
matematicos
deﬁnicion
originalmente
termino
machine
learning
acunado
arthur
lee
samuels
pionero
area
inteligencia
artiﬁcial
juegos
computadora
deﬁnio
la
habilidad
computadoras
aprender
ser
explıcitamente
programadas
tom
mitchel
formalizo
deﬁncion
terminos
matematicos
racio
nales
indicando
que
se
dice
programa
computadora
aprende
experiencia
si
conjunto
tareas
t
realiza
medicion
performance
p
dicha
performance
incrementada
experiencia
e
capitulo
conceptos
machine
learning
donde
tarea
t
consiste
basicamente
deﬁnir
tareas
ejecutaran
resolver
problema
mundo
real
cuales
podrıan
ser
clasiﬁcacion
categorizacion
regresion
agrupamiento
clustering
experiencia
obtie
nen
algoritmos
machine
learning
modelos
partir
aprenden
conjunto
datos
proceso
ir
ganando
experiencia
iterativo
conocido
entrenamiento
modelo
cuanto
performance
p
medida
cuantitativa
metrica
determinar
tan
bien
algoritmo
modelo
esta
eje
cutando
tarea
t
experiencia
e
medidas
tıpicas
utilizadas
precision
exactitud
etc
surgimiento
machine
learning
menciono
seccion
referida
avance
inteligencia
artiﬁcial
idea
maquinas
conscientes
inteligentes
nuevo
embargo
gra
cias
avances
ultimos
anos
posible
procesar
grandes
volumenes
datos
escala
igual
ası
podrıa
decir
vivimos
in
formacion
principales
desafıos
empresas
organizaciones
poder
obtener
informacion
partir
datos
permita
tomar
mejores
decisiones
datadriven
decisions
poder
tomar
decisiones
inteligentes
partir
gran
cantidad
datos
alcanza
paradigmas
programacion
tradicionales
programador
deberıa
contar
conocimiento
amplio
dominio
esta
trabajando
poder
determinar
todas
correlaciones
existentes
distintas
variables
datos
luego
deberıa
invertir
tiempo
codiﬁcacion
conjuntos
reglas
extremadamente
complejos
intentar
llevar
cabo
cualquier
tipo
analisis
un
sistema
basado
reglas
datos
disponibles
aproxima
cion
presenta
varias
deﬁciencias
lado
ciertas
relaciones
podrıan
ser
menos
evidentes
podrıan
ser
pasadas
alto
lado
tipo
sistemas
costosos
mantener
cualquier
cambio
introduzca
crear
nueva
regla
modiﬁcar
eliminar
existente
costoso
puede
introducir
errores
ası
surgio
concepto
machine
learning
aprendizaje
automatico
necesidad
tomar
decisiones
mas
rapidamente
mejor
calidad
diferencia
paradigmas
tradicionales
basados
reglas
machine
learning
utiliza
conjunto
datos
denominados
observaciones
construccion
modelo
mo
delo
utilizara
dichos
datos
deducir
todas
posibles
patrones
correlaciones
existentes
ellos
partir
conocimiento
adquirido
modelo
sera
capaz
predecir
valores
salida
nuevas
observaciones
vistas
anteriormente
proceso
aprendizaje
modelo
consta
basicamente
dos
etapas
etapas
proceso
machine
learning
training
entrenamiento
objetivo
aprender
partir
conjunto
datos
conocidos
ello
deben
utilizar
conceptos
matematicos
principal
mente
algebra
lineal
estadıstica
algoritmos
aprendizaje
testing
evaluacion
partir
aprendido
etapa
anterior
etapa
predicen
inﬁeren
resultados
acuerdo
nuevos
datos
dos
etapas
entrenamiento
evaluacion
tambien
conocidos
aprendizaje
prediccion
respectivamente
etapas
proceso
machine
learning
proceso
machine
learning
podrıa
ser
generalizado
tres
grandes
tareas
representacion
consiste
representar
problema
utilizando
lenguaje
formal
primera
etapa
seleccionara
algoritmo
machi
ne
learning
utilizara
ejemplo
observando
datos
determina
problema
regresion
entonces
probable
elija
regresion
lineal
modelo
representarlo
existen
diferentes
tipos
modelos
cuales
pueden
ser
clasiﬁcados
acuerdo
categorıas
nomenclaturas
basan
algoritmo
aprendizaje
utilizan
metodo
emplean
construirlos
ejemplo
mode
puede
ser
lineal
lineal
parametricos
parametricos
supervisado
supervisado
semisupervisado
modelo
ensamble
incluso
mode
basado
deep
learning
etapa
tambien
seleccionan
parametros
pesos
coeﬁcientes
modelo
seran
utilizados
evaluacion
vez
decidida
representacion
posibles
modelos
ne
cesitara
algun
criterio
evaluarlos
y
modo
poder
seleccionar
mejor
dentro
conjunto
candidatos
general
utilizan
metricas
retornan
algun
valor
performance
numerico
ayude
decidir
efectividad
candidato
optimizacion
etapa
ﬁnal
proceso
optimizacion
optimizacion
puede
describir
busqueda
traves
todas
combinaciones
posi
bles
hiperparametros
encontrar
aquella
de
resultado
modelo
mas
optimo
conjunto
datos
conjunto
datos
utilizaran
algoritmos
esta
compuesto
serie
observaciones
dominio
esta
estudiando
vez
obser
vaciones
estan
conformadas
variables
independientes
tambien
conocidas
capitulo
conceptos
machine
learning
input
variables
features
distintas
caracterısticas
propias
observa
cion
variable
dependiente
denominada
tambien
target
label
output
representa
aquella
caracterıstica
dominio
desea
estudiar
formalmente
variables
independientes
denotan
letra
x
subındi
ce
identiﬁca
manera
x
x
xn
conforman
totalidad
variables
independientes
conjunto
datos
lado
variable
dependiente
comunmente
denotada
letra
y
ası
podemos
formular
si
guiente
ecuacion
f
x
ϵ
formula
anterior
expresa
variable
dependiente
terminos
fun
cion
f
variables
independientes
x
x
xn
ﬁja
desconocida
tambien
incluye
termino
error
independiente
x
cuya
media
vera
mas
adelante
cero
f
representa
informacion
sistematica
variable
x
genera
respecto
pero
mencionado
funcion
f
suele
ser
desconocida
debe
ser
estimada
partir
informacion
observaciones
disponen
tipos
estimacion
existen
dos
grandes
razones
justiﬁcan
necesidad
estimar
f
predecir
inferir
predicciones
escenarios
dispone
gran
numero
observaciones
dis
tintas
variables
independientes
x
embargo
valor
puede
ser
difıcil
obtener
siguiendo
bajo
asuncion
termino
error
ϵ
tiende
ser
cero
po
sible
formular
ˆy
ˆf
x
ˆf
representa
estimacion
funcion
f
ˆy
prediccion
obtiene
y
contexto
forma
exacta
ˆf
necesariamente
importante
puede
verse
caja
negra
realmente
importa
produzca
predicciones
suﬁciente
aproximadas
y
ejemplo
puede
suponer
variables
independientes
x
x
xn
re
presentan
distintas
caracterısticas
muestra
sangre
paciente
variable
dependiente
riesgo
paciente
sufra
severa
reaccion
adversa
tipos
estimacion
determinado
medicamento
particular
modo
resulta
importante
poder
estimar
ﬁn
evitar
suministro
droga
aquellos
pacientes
prediccion
arroje
valor
alto
dicha
prediccion
ˆy
tendra
precision
estara
marcada
dos
valores
error
reducible
error
irreducible
mencionado
anteriormente
estimacion
ˆf
funcion
f
sera
perfecta
error
produzca
estimacion
denomina
error
reducible
modelo
utilizado
puede
ser
potencialmente
mejorado
au
mentar
precision
reducir
error
embargo
mejore
modelo
siempre
habra
pequeno
error
debe
variable
dependiente
esta
tambien
deﬁnida
termino
error
ϵ
ejemplo
anterior
error
esta
asociado
factores
tales
salud
general
paciente
dıa
particular
pequenas
variaciones
fabricacion
medicamento
es
tos
factores
pueden
ser
medidos
modelo
conocidos
error
irreducible
puede
ser
eliminados
retomando
ecuacion
podemos
plantear
siguiente
ecuacion
ey
ˆy
e
f
x
ϵ
ˆf
x
f
x
ˆf
x
reducible
varϵ
irreducible
primer
termino
expresion
representa
esperanza
cuadrado
diferencia
valor
real
predicho
f
termino
importante
conforma
base
tecnica
calculo
errores
diversos
modelos
conocida
mean
squared
error
inferencias
ciertos
casos
foco
esta
puesto
predecir
valor
sino
entender
relacion
existen
variables
independientes
variable
dependiente
decir
como
cambia
funcion
x
x
xn
contexto
ˆf
puede
ser
vista
caja
negra
debe
conocerse
forma
exacta
posee
puntos
mas
importantes
deben
ser
estudiados
son
que
variables
independientes
estan
asociadas
dependiente
que
grado
analisis
puede
determinar
solo
pequeno
subconjunto
atributos
estan
realmente
relacionados
variable
dependiente
esto
ademas
proveer
valiosa
informacion
permitirıa
reducir
complejidad
modelo
cual
relacion
variables
independientes
variable
indepen
diente
solo
importante
descubrir
aquellos
atributos
guardan
alta
correlacion
variable
dependiente
tambien
necesario
entender
capitulo
conceptos
machine
learning
naturaleza
dicha
relacion
incrementos
determinadas
variables
indepen
dientes
pueden
conducir
incrementos
decrementos
variable
target
variables
independientes
pueden
tener
efecto
opuesto
que
tan
compleja
dicha
relacion
vez
identiﬁcadas
correlaciones
mas
importantes
establecido
que
manera
inﬂuyen
importante
deter
minar
suﬁcientemente
simples
ser
modeladas
traves
ecuaciones
lineales
relacion
mas
compleja
tipo
modelo
necesario
ejemplos
tıpicos
inferencia
observan
areas
ﬁnanzas
marketing
ventas
estudian
distintas
caracterısticas
hacen
produc
to
venda
mejor
quiere
analizar
como
inﬂuye
rentabilidad
negocio
factores
ubicacion
proximidad
competencia
precios
esquemas
descuentos
metodos
estimacion
f
terminos
generales
existen
dos
formas
estimar
f
pueden
ser
caracteri
zados
metodos
parametricos
metodos
parametricos
metodo
parametrico
metodo
parametrico
consta
dos
pasos
realiza
alguna
asuncion
forma
f
primera
asuncion
bastante
frecuente
f
forma
lineal
manera
puede
expresar
f
siguiente
manera
f
x
β
βx
βx
βnxn
dado
distintos
valores
variables
independientes
x
x
xn
conocidos
tarea
estimar
f
reduce
signiﬁcativamente
lugar
tener
estimar
funcion
n
dimensional
aleatoria
solo
necesario
esti
mar
n
coeﬁcientes
vez
dispone
modelo
siguiente
paso
consiste
utilizar
informacion
observaciones
poseen
entrenar
modelo
caso
modelo
lineal
presentado
ecuacion
tarea
consiste
estimar
coeﬁcientes
β
β
βn
modo
tal
que
β
βx
βx
βnxn
balance
precision
interpretabilidad
metodo
parametrico
diferencia
metodos
parametricos
parametricos
realizan
nin
guna
asuncion
cuanto
ﬁgura
f
sino
eje
esta
puesto
encontrar
estimaciones
f
mas
aproximen
valor
real
presenta
ventaja
importante
dado
que
asumir
linealidad
modelos
parametricos
posibilidad
adaptarse
mejor
grupo
mas
variado
formas
f
balance
precision
interpretabilidad
existen
distintos
tipos
metodos
estimacion
f
producen
modelos
mas
restrictivos
caso
regresiones
lineales
mencionado
solo
capaces
producir
funciones
lineales
menos
restrictivos
adaptan
mejor
familia
mas
amplia
problemas
modelos
menos
ﬂe
xibles
bien
mas
faciles
entender
visualizar
producen
resultados
menos
acertados
teorıa
razonable
suponer
siempre
elegirıa
aquellos
mode
producen
mejores
estimaciones
pero
practica
este
siempre
caso
existen
diversas
razones
podrıa
preferir
metodo
inﬂexible
ejemplo
casos
inferencias
estudia
correlacion
variables
independientes
dependiente
puede
ser
preferible
sacriﬁcar
cierto
nivel
precision
objetivo
obtener
modelo
mas
simple
entender
transmitir
evaluacion
precision
modelo
muchas
veces
utilizacion
algun
metodo
aprendizaje
puede
lograr
buenos
resultados
conjunto
determinado
datos
pueden
in
cluso
resultar
mejor
conjunto
peor
otros
resulta
importante
poder
establecer
dado
conjunto
datos
tiene
que
metodo
produce
mejor
resultado
calidad
ajuste
quality
of
ﬁt
principales
medidas
pueden
tomar
evaluar
performan
ce
modelo
frente
conjunto
observaciones
consiste
evaluar
que
tan
aproximadas
predicciones
respecto
valores
reales
mo
delos
regresion
tecnica
usada
mas
frecuentemente
calculo
error
cuadratico
medio
mean
squared
error
dado
siguiente
formula
n
n
i
yi
ˆf
xi
capitulo
conceptos
machine
learning
ˆf
xi
prediccion
ˆf
iesima
observacion
mse
por
siglas
ingles
sera
pequeno
mientras
valores
predicciones
man
relativamente
cercanos
verdaderos
valores
y
error
cuadratico
medio
puede
ser
computado
training
set
lo
conoce
training
mse
poder
tener
primera
impresion
que
tan
pre
ciso
modelo
embargo
calculo
realmente
importante
dado
realmente
interesa
conocer
que
tan
acertadas
seran
predicciones
frente
informacion
nueva
matematicamente
ˆf
estimada
partir
training
set
observaciones
x
y
x
y
xn
yn
ası
obtienen
estimaciones
ˆf
x
ˆf
x
ˆf
xn
es
tas
estimaciones
bastante
cercanas
y
y
yn
tendra
training
mse
ba
jo
embargo
interes
esta
saber
ˆf
x
y
sino
determinar
ˆf
x
y
x
y
observacion
nueva
utilizada
entrena
miento
modelo
luego
procesar
numero
considerable
observaciones
utilizadas
fase
entrenamiento
puede
calcular
test
mse
como
avey
ˆf
x
x
y
todas
observaciones
nuevas
ave
calculo
pro
medio
average
dichas
observaciones
funcion
anterior
es
simplemente
forma
expresar
calculo
error
cuadratico
medio
mostro
ecua
cion
desafortunadamente
siempre
cuenta
test
set
debe
elegirse
alternativa
calcular
test
mse
casos
suele
hacer
tomar
training
mse
asumiendo
modelo
arrojara
test
set
predicciones
mse
semejante
obtenido
etapa
entrenamiento
existe
problema
fundamental
estrategia
ninguna
garantıa
modelo
produjo
fase
entrenamiento
mse
mas
pequeno
tambien
haga
etapa
test
calidad
ajuste
clasiﬁcacion
seccion
anterior
hablo
calidad
ajuste
modelos
regre
sion
embargo
conceptos
enunciados
tambien
aplican
mo
delos
clasiﬁcacion
sola
modiﬁcacion
ahora
yi
numerica
ejemplo
busca
estimar
f
bases
observaciones
en
trenamiento
x
y
xn
yn
ahora
y
yn
cualitativos
forma
mas
comun
cuantiﬁcar
precision
estimador
ˆf
error
rate
entrena
miento
representa
proporcion
errores
utilizara
estimador
ˆf
observaciones
conjunto
entrenamiento
encuentra
dada
por
evaluacion
precision
modelo
n
n
i
iyi
ˆyi
donde
ˆyi
label
clase
predicha
observacion
iecima
utilizando
estimador
ˆf
iyi
ˆyi
indicador
variable
yi
ˆyi
yi
ˆyi
iyi
ˆyi
igual
entonces
iecima
observacion
clasiﬁcada
correctamen
metodo
clasiﬁcacion
caso
contrario
clasiﬁcada
incorrectamente
tanto
ecuacion
computa
fraccion
clasiﬁcaciones
incorrectas
ecua
cion
hace
referencia
training
error
rate
computada
basada
datos
usados
entrenar
clasiﬁcador
igual
caso
regresion
lineal
interes
centrado
propor
cion
errores
resultan
aplicar
clasiﬁcador
observaciones
test
utilizadas
entrenamiento
test
error
rate
asociado
conjunto
observaciones
test
forma
x
y
esta
dado
por
aveiy
ˆy
donde
ˆy
label
clase
predicho
resulta
aplicar
clasiﬁcador
observaciones
test
predicador
x
buen
clasiﬁcador
sera
aquel
error
test
mas
pequeno
overﬁtting
underﬁtting
esta
entrenando
modelo
deseable
mismo
menor
train
mse
posible
embargo
continua
aumentando
ﬂexibilidad
mo
delo
solo
objetivo
reducir
valor
modelo
trabajara
manera
intensa
aprender
puede
observaciones
dado
empe
zara
adaptarse
incorporar
el
pequenas
variaciones
observaciones
pueden
dadas
ﬂuctuaciones
azarosas
balance
sesgo
varianza
dos
medidas
relacionan
capacidad
ajuste
generalizacion
modelo
logra
buen
ajuste
diferencia
datos
reales
estimacion
modelo
pequena
cuyo
caso
sesgo
tambien
sera
pequeno
buenos
resultados
van
mano
aumento
complejidad
modelo
aumenta
complejidad
modelo
vuelve
sensible
pequenas
variaciones
datos
entrada
ﬂuctuando
funcion
datos
varianza
aumenta
razon
sera
importante
encontrar
balance
sesgo
varianza
capitulo
conceptos
machine
learning
terminos
mas
formales
sesgo
varianza
pueden
ser
descriptos
como
varianza
reﬁere
cantidad
ˆf
variarıa
entrenado
modelo
training
set
diferente
dado
modelo
aprende
partir
datos
suministrados
etapa
entrenamiento
natural
supo
ner
distintos
datos
produciran
modelo
distinto
observa
va
rianza
alta
quiere
decir
pequenos
cambios
training
data
tendran
alto
impacto
estimacion
ˆf
general
asume
cuanto
mas
ﬂexible
metodo
mas
alta
varianza
luego
haber
analizado
subseccion
deberıa
resultar
intuitivo
mas
ﬂexible
metodo
mas
tratara
ajustarse
cada
observaciones
disponibles
sesgo
error
inherente
existe
modelo
querer
representar
problema
complejo
realidad
palabras
sesgo
presenta
medida
evaluar
que
tan
bien
metodo
adapta
realidad
esta
intentando
modelar
caso
relacion
ﬂexibilidad
modelo
inversamente
proporcional
metodo
mas
ﬂexible
producira
sesgo
menor
modo
test
mse
esta
dado
velocidad
crecimientodecrecimiento
cada
dos
propiedades
puede
ser
expresado
matematicamente
siguiente
manera
bias
ˆf
x
ˆf
x
f
x
ﬁgura
figura
permite
observar
graﬁcamente
impacto
varianza
sesgo
modelo
varianza
alta
producira
valores
mas
dispersos
lado
sesgo
elevado
producira
valores
mas
alejado
centro
el
valor
real
clasiﬁcacion
metodos
aprendizaje
figura
sesgo
varianza
clasiﬁcacion
metodos
aprendizaje
metodos
aprendizaje
pueden
ser
clasiﬁcados
cuatro
grandes
categorıas
aprendizaje
supervisado
metodos
algoritmos
aprendizaje
super
visado
realizan
entrenamiento
datos
entrada
conjunto
en
trenamiento
respectivos
datos
salida
conocido
etiqueta
la
bel
expresado
terminos
matematicos
idea
consiste
algoritmo
pueda
aprender
relaciones
existen
variables
independientes
x
x
xn
variable
dependiente
y
modo
utilizar
aprendiza
je
realizar
predicciones
nuevos
datos
datos
desconocidos
aprendizaje
supervisado
aprendizaje
supervisado
requiere
mo
delo
entrenado
serie
observaciones
variables
in
dependientes
dependiente
embargo
casos
in
formacion
variable
dependiente
desconocida
imposible
entrenar
modelo
situaciones
modelo
super
visado
extremadamente
util
algoritmos
intentan
aprender
cuales
relaciones
patrones
estructuras
internas
inherentes
datos
ningun
tipo
ayuda
supervision
caso
aprendizaje
supervisado
aprendizaje
supervisado
concentra
mas
intentar
extraer
concocimien
to
informacion
util
datos
mas
predecir
salidas
aprendizaje
semisupervisado
metodos
aprendizaje
semisupervisados
combinacion
metodos
supervisados
supervisados
metodos
normalmente
utilizan
entrenamiento
gran
cantidad
capitulo
conceptos
machine
learning
datos
poseen
etiqueta
pequena
si
existen
multiples
tecnicas
disponibles
forma
metodos
generativos
graﬁcos
basados
metodos
metodos
basados
heurıstica
etc
aprendizaje
refuerzos
caso
metodos
aprendizaje
re
fuerzos
agente
quiere
entrenar
ambiente
determinado
perıodo
tiempo
modo
ir
mejorando
performance
basandose
acciones
este
ejecuta
dicho
ambien
te
normalmente
agente
comienza
conjunto
estrategias
reglas
interactuar
ambiente
observar
dicho
ambiente
toma
acciones
particulares
basandose
reglas
polıticas
observando
actual
ambiente
acuerdo
accion
tomo
agente
obtiene
recom
pensa
penalizacion
proceso
iterativo
algoritmo
ira
aprendiendo
modiﬁcando
estrategia
ser
necesario
modo
obtener
recompensa
deseada
categorizacion
metodos
aprendizaje
posible
categorizar
metodos
aprendizaje
acuerdo
tipo
salida
desea
obtener
algoritmos
machine
learning
clasiﬁcacion
modelos
clasiﬁcacion
encuentran
dentro
meto
dos
aprendizaje
supervisado
objetivo
principal
predecir
categorıa
etiqueta
cada
datos
entrada
basandose
modelo
aprendido
etapa
entrenamiento
etiquetas
salida
tambien
conocidas
clases
etiquetas
clase
cuales
natura
leza
categoricas
poseen
orden
discretas
tanto
cada
etiqueta
salida
pertenecera
clase
categorıa
discreta
especıﬁca
existe
amplia
variedad
algoritmos
pertenecen
familia
quizas
mas
importantes
son
modelos
lineales
ejemplo
logistic
regression
regresion
logısti
ca
naıve
bayes
support
vector
machines
modelos
prametricos
k
vecinos
mas
cercanos
knearest
neigh
bors
metodos
basados
arboles
arboles
decision
decision
trees
metodos
ensamble
random
forest
gradient
boosted
machines
boosting
redes
neuronales
modelos
clasiﬁcacion
tambien
pueden
ser
caracterizados
clase
pertenece
dato
salida
cantidad
categorizacion
metodos
aprendizaje
clasiﬁcacion
binaria
dos
categorıas
di
ferenciar
entonces
problema
clasiﬁcacion
binaria
ejemplo
clasiﬁcacion
binaria
podrıa
ser
problema
clasiﬁcacion
emails
problema
desea
distinguir
dos
categorıas
es
spam
no
spam
clasiﬁcacion
multiclases
considera
extension
problema
cla
siﬁcacion
binario
caso
mas
dos
categorıas
clases
dato
puede
pertenecer
ejemplo
problema
clasiﬁcacion
multiclases
determinar
categorıa
dıgitos
cero
nueve
escritos
mano
cual
problema
clasiﬁcacion
diez
clases
clasiﬁcacion
multietiqueta
problemas
clasiﬁcacion
normal
mente
involucran
datos
pueden
pertenecer
mas
categorıa
poseer
mas
etiqueta
label
ejemplo
prediccion
ca
tegorıa
artıculos
novedades
pueden
tener
multiples
etiquetas
polıtica
ciencia
religion
etc
regresion
igual
modelos
clasiﬁcacion
estos
pertenecen
cate
gorıa
algoritmos
aprendizaje
supervisados
lugar
predecir
valor
discreto
modelos
predicen
valores
reales
continuos
metodos
basados
regresiones
entrenados
partir
conjunto
observacio
nes
cada
conformada
conjunto
variables
independientes
valor
continuo
dependiente
ası
modelo
hara
uso
valores
pa
ra
aprender
relaciones
existen
features
target
partir
conocimiento
modelo
sabra
predecir
nuevos
valores
continuos
suministradas
nuevas
observaciones
vista
anteriormente
modelos
regresiones
mas
importantes
son
regresion
lineal
simple
simple
linear
regression
tipo
mo
delos
solo
variable
independiente
dependiente
variable
dependiente
valor
real
normalmente
sigue
dis
tribucion
normal
modelos
regresion
asume
existe
relacion
lineal
variable
independiente
dependiente
regresion
lineal
multiple
multiple
linear
regression
considerada
extension
modelo
regresion
lineal
simple
incluye
mas
variable
independiente
igual
modelo
lineal
simple
prediccion
valor
real
sigue
distribucion
normal
regresion
lineal
no
linear
regression
modelo
regresion
coeﬁcientes
lineales
puede
ser
considerado
modelo
regresion
lineal
ejemplo
considerese
β
log
βx
ε
modelos
difıciles
aprender
utilizados
capitulo
conceptos
machine
learning
clustering
clustering
pertenece
modelos
algoritmos
supervi
sados
cuyo
proceso
consiste
agrupar
datos
similares
previamente
etiquetados
clasiﬁcados
salidas
tipo
modelos
grupos
datos
segregados
similares
sı
diferentes
miembros
demas
grupos
mayor
diferencia
existe
mo
delos
supervisados
aquı
datos
previamente
clasiﬁcados
entrenar
modelo
utiliza
conjunto
datos
entrada
modelos
clustering
pueden
ser
diferentes
tipos
acuerdo
metodologıas
principios
clustering
basado
particion
metodo
clustering
basado
par
ticion
deﬁnira
nocion
similaridad
similaridad
ca
racterıstica
deriva
atributos
entrada
luego
aplicadas
funciones
matematicas
luego
vez
encontradas
similitudes
agrupan
datos
similares
solo
grupo
separados
aquellos
diferentes
modelos
clustering
basados
par
ticion
general
desarrollados
utilizando
tecnicas
recursivas
clasiﬁcarlos
ejemplo
comienza
porcion
arbitraria
datos
y
basados
alguna
medida
similitud
continua
reasignando
datos
llegue
punto
estable
segun
algun
criterio
ejem
plos
tecnicas
son
kmeans
kmedoids
clarans
etc
clustering
jerarquico
tipo
modelos
diferencian
clustering
basado
particion
manera
desarrollados
como
trabajan
dentro
paradigma
clustering
jerarquico
comienza
con
bien
datos
solo
grupo
divisive
clustering
datos
diferentes
grupos
aglomerativo
segun
punto
entrada
ele
gido
continua
dividiendo
gran
grupo
grupos
mas
pequenos
clusters
basados
algun
criterio
similitud
bien
puede
continuar
juntando
diferentes
grupos
clusters
grupos
mas
grandes
basados
mismo
criterio
proceso
concluye
llega
condicion
preestablecida
clustering
basado
densidad
ambos
metodos
mencionados
fuertemente
dependientes
nocion
distancia
conduce
es
tos
algoritmos
encontrar
clusters
datos
forma
esferica
puede
ser
problema
datos
encuentran
ubicados
arbitrariamente
limitacion
podrıa
ser
resuelta
lugar
tener
cuenta
concep
to
distancia
utilizara
concepto
densidad
datos
desarrollar
modelo
entonces
metodologıa
encontrar
puntos
consiste
encontrar
puntos
proximos
particular
sino
mas
bien
determinar
areas
contengan
puntos
tipo
mode
resultan
simples
interpretar
metricas
distancia
resumen
ayudan
clusters
necesariamente
forma
esferica
ejemplos
modelos
dbscan
optics
resumen
comenzo
capıtulo
deﬁniendo
machine
learning
razon
surgimiento
tambien
menciono
como
compone
conjunto
datos
utiliza
di
chos
algoritmos
seguidamente
abordaron
conceptos
relacionados
tipos
estimacion
pueden
presentar
metodos
existen
evaluacion
pre
cision
modelo
balance
medidas
sesgo
varianza
ultimo
estudiaron
cuales
distintos
metodos
aprendizaje
pueden
encontrarse
como
encuentran
categorizados
capıtulo
encuentra
continuacion
abordara
mayor
detalle
metodos
tecnicas
pertenecientes
diferentes
modelos
clasiﬁca
cion
existentes
cuales
metricas
utilizan
evaluacion
capitulo
modelos
clasiﬁcacion
perspectiva
machine
learning
problema
deteccion
malware
identiﬁcacion
familias
cada
muestras
pueden
ser
considerados
problemas
clasiﬁcacion
caso
deteccion
malware
intenta
identiﬁcar
muestra
es
efecto
programa
malicioso
clasiﬁcacion
binaria
muestra
malware
caso
clasiﬁcacion
familias
problema
multiclase
dado
debe
determinarse
cual
nueve
familias
pertenece
muestra
continuacion
dara
marco
teorico
metodos
tecnicas
pertenecientes
categorıa
modelos
cuales
seran
utilizados
investiga
cion
logistic
regression
logistic
regression
algoritmo
puede
ser
utilizado
resolver
pro
blemas
regresion
clasiﬁcacion
logistic
regression
tambien
conocido
logic
regression
comunmente
utilizado
estimar
probabilidad
ins
tancia
pertenezca
clase
particular
probabilidad
estimada
ma
yor
entonces
modelo
predice
instancia
pertenece
clase
llamada
clase
positiva
etiqueta
predice
clase
pertenece
en
cuyo
caso
clase
sera
negativa
etiqueta
convierte
clasiﬁcador
binario
simple
utilizar
comprender
resulta
efectivo
problemas
cuales
conjunto
variables
entrada
bien
conocidas
ademas
encuentran
fuertemente
correlacionadas
salidas
aunque
resulta
tan
efec
tivo
variables
entrada
bien
conocidas
relaciones
dichas
variables
complejas
capitulo
modelos
clasiﬁcacion
knearest
neighbors
algoritmo
knearest
neighbors
quizas
mas
sencillos
imple
mentar
dado
conjunto
entrenamiento
datos
etiquetados
funcion
distancia
knn
clasiﬁca
punto
x
basandose
k
elementos
dicho
conjunto
encuentren
mas
cerca
x
figura
conjunto
datos
etiquetado
ejemplo
considera
graﬁco
figura
dicho
conjunto
entre
namiento
consta
diez
elementos
tipo
cırculo
azul
cuatro
tipo
cuadrados
rojos
figura
a
nearest
neighbor
nn
knearest
neighbors
figura
b
nearest
neighbor
nn
quisiera
clasiﬁcar
diamante
gris
etiquetado
x
figu
ra
utilizando
nn
donde
k
dado
que
punto
mas
cercano
x
cua
drado
rojo
etiquetado
b
x
serıa
clasiﬁcado
cuadrado
rojo
lado
quisiera
clasiﬁcar
x
utilizando
nn
muestra
figura
puede
observar
existen
tres
puntos
cercanos
x
con
respecto
distancia
euclides
cuadrado
rojo
etiquetado
b
dos
cırculos
azules
etiquetados
r
r
respectivamente
dado
mayorıa
puntos
mas
cercanos
x
cırculos
rojos
este
serıa
clasiﬁcado
mismo
tipo
numero
vecinos
mas
cercanos
k
medida
distancia
componentes
clave
algoritmo
knearest
neighbors
valor
pequeno
k
resultara
baja
precision
conjuntos
datos
ruido
dado
ca
da
instancia
conjunto
entrenamiento
alto
peso
proceso
decision
valor
grande
k
disminuye
performance
algoritmo
ademas
valor
grande
modelo
puede
hacer
sobreajuste
overﬁtting
diﬁcual
tando
separacion
clases
tambien
resultarıa
menos
precision
buena
regla
utilizar
k
menor
raız
cuadrada
n
n
numero
total
patrones
entrenamiento
existen
diferentes
metricas
calculo
distancia
vecinos
mas
cer
canos
mas
conocidas
distancia
hamming
distancia
manhattan
dis
tancia
minkowsky
distancia
euclides
metodo
mas
utilizado
trata
variables
continuas
donde
toman
dos
observaciones
espacio
ndimensional
x
x
xn
x
x
xn
distancia
euclides
dos
puntos
esta
dada
por
distx
x
n
i
xi
xi
capitulo
modelos
clasiﬁcacion
distancia
euclides
funciona
bien
problemas
atributos
mismo
tipo
atributos
diferente
tipo
recomendable
utilizar
distancia
manhattan
bien
facilidad
sencillez
implementar
aspecto
positivo
tipo
algoritmos
resultan
aptos
casos
conjunto
datos
encuentra
desigualmente
distribuido
algoritmo
knearest
neighbors
tendra
buena
perfomance
debe
que
clase
domina
ampliamente
demas
probable
tener
mas
vecinos
clase
debido
gran
tamano
llevara
tener
predicciones
incorrectas
naıve
bayes
naive
bayes
algoritmo
clasiﬁcacion
machine
learning
utiliza
teo
rema
bayes
mismo
puede
ser
utilizado
problemas
clasiﬁcacion
binario
multiclases
objetivo
principal
metodo
tratar
cada
atributo
independientemente
evaluando
probabilidad
cada
tener
cuenta
ninguna
correlacion
hacer
prediccion
basandose
teorema
bayes
motivo
llamado
naıve
ingenuo
espanol
problemas
mundo
real
siempre
existe
algun
tipo
correlacion
atributos
comprender
mejor
algoritmo
bayes
necesario
introducir
conceptos
probabilidad
clase
probabilidad
clase
dataset
conjunto
datos
palabras
selecciona
manera
aleatoria
elemento
dataset
probabilidad
pertenecer
cierta
clase
probabilidad
condicional
probabilidad
valor
atributo
dada
clase
donde
probabilidad
clase
calculada
simplemente
numero
observaciones
clase
dividido
numero
total
observaciones
pc
cantidad
instancias
c
cantidad
instancias
total
probabilidad
condicional
calculada
frecuencia
cada
valor
atri
buto
dividido
frecuencia
instancias
clase
pvc
cantidad
instancias
v
c
cantidad
instancias
v
support
vector
machines
dadas
probabilidades
podra
ahora
calcular
probabilidad
instancia
perteneciente
clase
manera
tomar
decisiones
utilizando
teorema
bayes
pab
pabpa
pb
probabilidades
cada
ıtem
pertenecientes
todas
clases
comparadas
clase
mas
alta
probabilidad
seleccionada
resultado
ventaja
utilizar
metodo
simplicidad
facilidad
entendimiento
ademas
posee
buena
performance
conjunto
datos
atributos
irrelevantes
probabilidades
contribuyan
salidas
bajas
mismas
tomadas
cuenta
realizan
predicciones
mas
aun
algoritmo
usualmente
resulta
buena
performance
terminos
uso
recursos
dado
solo
necesita
calcular
probabilidades
atributos
clases
necesidad
encontrar
ningun
coeﬁciente
algoritmos
support
vector
machines
support
vector
machines
svm
algoritmo
machine
learning
utilizado
generalmente
resolver
problemas
clasiﬁcacion
objetivo
principal
svm
encontrar
hiperplano
separe
clases
mejor
manera
posible
hiperplano
deﬁnido
subespacio
dimension
menos
espacio
esta
trabajando
ejemplo
datos
cuales
estan
trabajando
viven
espacio
bidimensional
hiperplano
simplemente
lınea
hiperplano
existe
dice
datos
linealmente
separables
figura
maximizacion
margen
capitulo
modelos
clasiﬁcacion
hora
elegir
hiperplano
svm
busca
maxi
mice
margen
margen
deﬁne
distancia
mınima
hiper
plano
cualquier
elemento
training
set
observa
figura
ﬂechas
representan
margen
svm
generalmente
resultan
buena
precision
incluso
conjun
to
datos
pequenos
adicionalmente
dataset
pequeno
modelo
ejecu
tara
rapidamente
tiempos
ejecucion
disparan
conforme
tamano
conjunto
datos
aumenta
decision
trees
igual
support
vector
machines
decision
trees
arboles
decision
algoritmos
machine
learning
versatiles
pueden
ejecutar
tareas
regresion
clasiﬁcacion
incluso
obtener
multiples
salidas
algoritmos
poderosos
capaces
ajustarse
complejos
conjuntos
datos
decision
tree
construye
dividiendo
manera
recursiva
conjunto
datos
secuencias
subconjuntos
basado
preguntas
estilo
sientonces
ifthen
conjunto
entrenamiento
consiste
pares
x
y
x
ird
d
corresponde
numero
atributos
disponibles
correspon
diente
etiqueta
metodo
aprendizaje
dividira
conjunto
entrenamiento
grupos
basandose
x
mientras
intenta
mantener
asignaciones
cada
grupo
tan
uniformes
posible
lograrlo
metodo
aprendizaje
debe
elegir
atributo
umbral
asociado
dicho
atributo
dividira
datos
proceso
entrenamiento
continuara
encontrar
condicion
ﬁn
decision
trees
faciles
construir
permiten
creacion
complejos
proce
sos
decision
resultados
intuitivos
interpretar
pueden
facil
mente
producir
overﬁtting
expandiendo
arbol
ramas
reﬂejan
outliers
conjunto
datos
manera
tratar
sobreajuste
podarel
modelo
evitando
crecimiento
ramas
superﬂuas
prepruning
removiendolas
luego
arbol
crecido
postpruning
metodos
ensamble
poder
resolver
problema
metodos
ensamblado
entrenan
multiples
modelos
aprendizaje
diferencia
metodos
tıpicos
producen
unico
modelo
luego
entrenamiento
objetivo
construir
conjunto
modelos
apenas
mejores
tirar
moneda
cuyos
resultados
puedan
ser
combinados
acuerdo
criterio
alcanzar
performance
casi
perfecta
metodos
ensamble
modo
ensamble
esta
compuesto
modelos
aprendizaje
basicos
debiles
implementan
algoritmo
tal
arbol
decision
red
neuronal
modelos
utilizan
mismo
algoritmo
basico
dice
ensamble
homogeneo
mientras
que
distintos
modelos
ejecutan
algoritmos
distinto
tipo
ensamble
conocido
heterogeneo
existen
dos
principales
metodologıas
metodos
ensamble
bagging
dentro
metodologıa
principal
objetivo
construir
varios
estimadores
independientemente
luego
promediar
predicciones
uti
lizar
tecnica
logra
dratica
reduccion
error
metodo
siempre
buscara
crear
modelos
mas
independientes
posible
ejemplo
algoritmos
utilizan
metodos
random
forest
boosting
diferencia
metodo
bagging
boosting
construira
estimadores
base
manera
secuencial
objetivo
reducir
sesgo
estimador
combinado
motivacion
convertir
modelos
aprendizaje
debiles
mo
delos
robustos
ejemplos
utilicen
tecnica
son
adaboost
gradient
boos
ting
xgboost
otros
random
forest
random
forest
algoritmo
aprendizaje
supervisado
ﬂexible
facil
usar
capaz
producir
buenos
resultados
aun
haber
realizado
ajuste
parametros
forestbosque
construye
ensamble
varios
decision
trees
normalmente
entrenado
utilizando
metodo
bagging
metodo
bagging
boostrap
aggregation
combinacion
varios
modelos
aprendizaje
cuyo
objetivo
consiste
reducir
alta
varianza
decision
tree
funcionamiento
consiste
basicamente
crear
varios
subconjuntos
datos
conjunto
entrenamiento
original
training
set
elegidos
manera
aleatoria
reemplazo
luego
cada
subconjunto
utiliza
entrenar
arboles
decision
dando
resultado
ensamble
diferentes
modelos
promedio
pre
dicciones
diferentes
arboles
utiliza
resulta
mas
robusto
solo
arbol
decision
capitulo
modelos
clasiﬁcacion
figura
constitucion
arboles
decicion
random
forest
como
particiona
conjunto
entrenamiento
principal
ventaja
clasiﬁcadores
random
forest
requieren
ajuste
tuning
aun
ası
capaces
proveer
forma
alcanzar
buen
equi
librio
sesgo
varianza
utilizado
promedio
aleatoriedad
ademas
rapidos
faciles
entrenar
paralelo
eﬁcaces
momento
predecir
diferencia
sencillos
arboles
decision
random
forest
intuitivos
pueden
resultar
mas
difıciles
interpretar
xgboost
xgboost
cuyo
nombre
proviene
extreme
gradient
boosting
implemen
tacion
algoritmo
aprendizaje
automatico
gradient
boosting
desarrollado
funcionar
manera
altamente
eﬁciente
ﬂexible
portable
gradient
boosting
tecnica
machine
learning
resolver
problemas
re
gresion
clasiﬁcacion
produce
modelo
ensamble
debil
normalemente
arbol
decision
modelo
construido
misma
manera
hacen
httpsxgboostreadthedocsioenlatest
redes
neuronales
artiﬁciales
redes
neuronales
profundas
algoritmos
boosting
nuevos
modelos
agregados
existentes
corregir
errores
modelos
incorporados
manera
secuencial
has
ta
detecte
mas
mejoras
realizar
tecnica
gradient
boosting
utiliza
descenso
gradiente
minimizar
perdida
agrega
nuevos
modelos
ahı
nombre
figura
evolucion
xgboost
decision
trees
redes
neuronales
artiﬁciales
redes
neuronales
pro
fundas
redes
neuronales
artiﬁciales
artiﬁcial
neural
network
redes
neuronales
profundas
deep
neural
network
pueden
ser
utilizadas
realizar
ta
reas
clasiﬁcacion
obtener
buenos
resultados
bien
pueden
resultar
mas
complejas
programar
existen
muchas
herramientas
frameworks
tensor
flow
desarrolladas
ﬁn
ayudar
programador
dicha
tarea
redes
neuronales
tomado
inspiracion
proceso
aprendizaje
ocurre
cerebro
humano
componen
red
funciones
llamadas
parametros
permitiran
red
aprender
cuales
vez
pueden
ajus
tar
tuning
mismos
mediante
analisis
datos
cada
parame
tros
tambien
conocidos
neuronas
funcioon
produce
salida
luego
haber
recibido
mas
entradas
luego
salidas
pasaran
siguiente
capa
neuronas
utilizara
entrada
funcion
ge
nerara
propia
salida
nuevas
salidas
enviaran
siguiente
capa
ası
proceso
continuara
sucesivamente
haber
considerado
todas
neuronas
httpswwwtensorfloworg
capitulo
modelos
clasiﬁcacion
conforman
red
neuronas
terminales
recibido
entrada
salidas
neuronas
terminales
sera
resultado
ﬁnal
modelo
figura
representacion
visual
red
neuronal
simple
redes
neuronales
pueden
ser
efectivas
problemas
alta
dimen
sionalidad
capaces
lidiar
complejas
relaciones
variables
conjuntos
categorıas
exhaustivas
complejas
funciones
relacionadas
entrada
sali
da
variables
cuentan
poderosas
opciones
tuning
evitar
overﬁtting
underﬁtting
bien
redes
pueden
resultar
robustas
poderosas
tambien
pueden
resultar
complejas
difıciles
implementar
aunque
puede
resolverse
facil
mente
utiliza
framework
pueden
ser
intuitivas
requieren
mano
experta
ser
ajustadas
casos
pueden
requerir
grandes
conjuntos
datos
ser
efectivas
evaluacion
modelos
clasiﬁcacion
matriz
confusion
matriz
confusion
formas
mas
conocidas
evaluar
modelos
clasiﬁcacion
aunque
matriz
sı
misma
metrica
representacion
puede
ser
utilizada
deﬁnir
variedad
metricas
pueden
resultar
importantes
dependiendo
escenario
matriz
confusion
puede
ser
utilizada
modelos
clasiﬁcacion
binaria
ası
tambien
multiclases
matriz
confusion
crea
partir
comparacion
etiqueta
pre
dijo
etiqueta
actual
posee
muestra
proceso
repite
datos
dataset
resultados
representados
matriz
dimension
evaluacion
modelos
clasiﬁcacion
dos
donde
primera
columna
contiene
suma
total
verdaderos
negativos
resultados
modelo
predijo
negativos
efecto
son
falsos
ne
gativos
resultados
modelo
predijo
negativos
eran
segunda
columna
contiene
suma
total
falsos
positivos
resultados
modelo
predijo
positivos
eran
verdaderos
positivos
resultados
modelo
predijo
positivos
positivos
dijo
anteriormente
matriz
sı
metrica
partir
resultados
arroja
pueden
calcular
ciertas
metricas
resultan
utiles
considera
tp
verdaderos
positivos
tn
verdaderos
negativos
fp
falsos
positivos
fn
falsos
negativos
entonces
accuracy
metricas
performance
mas
populares
dentro
modelos
clasiﬁcacion
deﬁne
proporcion
predicciones
correctas
realizadas
modelo
accuracy
tp
tn
tp
fp
tn
fn
precision
metrica
deriva
matriz
confusion
deﬁne
numero
predicciones
hechas
realmente
correctas
total
predicciones
positivas
precision
tp
tp
fp
recall
medida
modelo
identiﬁca
porcentaje
datos
rele
vantes
deﬁne
numero
instancias
clase
positiva
correctamente
predichas
recall
fp
tp
fn
f
score
casos
quiere
optimizacion
balanceada
precision
sensibilidad
f
score
precision
recall
precision
recall
receiver
operating
characteristic
curve
roc
siglas
ingles
concepto
proviene
originalmente
uso
radares
concepto
puede
extender
modelos
clasiﬁcacion
binarios
multiclases
puede
ser
interpretada
efectividad
modelo
puede
distinguir
senal
verdadera
ruido
datos
capitulo
modelos
clasiﬁcacion
curva
roc
crea
dibujando
fraccion
verdaderos
positivos
versus
frac
cion
falsos
positivos
mayormente
aplicable
clasiﬁcadores
scoring
clasi
ﬁcadores
scoring
tipo
clasiﬁcador
retorna
valor
probabili
dad
score
cada
clase
label
curva
roc
funciona
siguiente
manera
ordenan
salidas
clasiﬁcador
ordenados
score
o
probabilidad
pertenecer
clase
positiva
comienza
coordenada
cada
valor
x
lista
ordenada
pregunta
a
x
positiva
mueve
pos
hacia
arriba
b
x
negativa
mueve
neg
hacia
derecha
pos
neg
fracciones
positivos
negativos
respectivamente
luego
traza
lınea
diagonal
indicara
curva
roc
encuentra
encima
quiere
decir
modelo
clasiﬁcacion
mejor
promedio
resumen
presente
capıtulo
explico
mayor
detalle
metodos
exis
tentes
machine
learning
clasiﬁcacion
comenzo
explicando
logistic
re
gression
metodo
simple
puede
ser
utilizado
regresion
clasiﬁcacion
binaria
luego
estudiaron
algoritmos
kneares
neighbors
naive
bayes
support
vector
machines
metodos
resultan
simples
implemen
tar
comprender
continuacion
abordo
algoritmo
decision
tree
que
igual
support
vector
machines
algoritmos
versatiles
pueden
ejecu
tar
tareas
regresion
clasiﬁcacion
tambien
explicaron
metodos
ensamble
random
forest
implementacion
algoritmo
gradient
boosting
xgboost
ultimo
describieron
redes
neuronales
artiﬁ
ciales
redes
neuronales
profundas
cuales
tambien
pueden
ser
utilizadas
taras
clasiﬁcacion
paso
ﬁnal
mencionaron
describieron
cuales
tecnicas
mas
uti
lizadas
evaluar
modelos
clasiﬁcacion
cuales
destacan
matriz
confusion
curva
roc
parte
ii
implementacion
capitulo
data
mining
generacion
dataset
capıtulo
enfoca
estudio
decisiones
diseno
implementacion
tecnicas
utilizadas
analisis
conjunto
datos
disponible
mo
do
comenzara
describiendo
estructura
formato
dichos
datos
crudos
ori
ginales
luego
pasar
enumerar
aquellos
atributos
considerados
mas
relevantes
vez
identiﬁcados
dichos
features
mencionaran
describiran
metodos
tecnicas
utilizadas
extraerlos
informacion
obtenida
sera
luego
conformara
dataset
utilizara
algoritmos
clasiﬁcacion
conjunto
inicial
datos
conjunto
inicial
datos
realizo
experimento
obtenido
sitio
kaggle
mismo
compone
conjunto
archivos
tipo
asm
correspondiente
archivo
tipo
bytes
equivalentes
aproximadamente
once
mil
malwares
cada
archivos
pertenece
nueve
clases
familias
virus
distinta
archivos
asm
archivos
asm
programas
escritos
lenguaje
ensamblador
almacenados
bajo
extension
asm
guarda
relacion
cercana
instrucciones
codigo
maquina
httpswwwkagglecomcmalwareclassification
capitulo
data
mining
generacion
dataset
textaf
b
ec
mov
ebp
esp
textb
ec
sub
esp
h
textb
d
c
lea
edx
unk_c
textba
fa
bf
d
cmp
edx
dbfh
textc
ed
jb
short
loc_af
textc
push
edx
textc
ff
b
e
push
dword
ptr
edxeh
textc
push
edi
textca
ff
push
dword
ptr
edxh
textcd
e
call
sub_
textd
c
c
add
esp
ch
textd
a
pop
edx
textd
push
edx
textd
ba
mov
edx
textdc
push
edx
textdd
e
call
sub_e
texte
ff
push
dsgetpriorityclass
texte
c
retn
texte
sub_ac
endp
spanalysis
failed
figura
extracto
archivo
aguvpoccafmyvdyfgbasm
nota
encabezados
pe
portable
executable
eliminados
cuestiones
seguridad
encabezados
poseen
estructura
particular
formados
serie
secciones
indican
dynamic
linker
como
debera
mapear
archivo
memoria
archivos
bytes
archivos
bytes
archivos
contienen
codigo
maquina
ejecuta
ble
representacion
hexadecimal
archivos
almacenan
bajo
extension
bytes
conjunto
inicial
datos
ff
f
ff
f
ff
d
ff
e
b
ec
ec
a
f
fc
bf
e
e
bb
b
c
bb
ff
ff
d
c
f
d
a
eb
d
f
ff
c
b
fc
f
ff
f
ff
f
ff
f
d
f
ff
b
f
f
f
b
f
be
f
e
bb
eb
b
f
b
c
c
e
b
f
f
a
d
e
f
b
c
c
b
ff
c
b
f
ff
c
f
a
c
e
a
e
d
c
e
c
e
d
da
e
e
bc
c
f
e
figura
extracto
archivo
anoozdnbpxirmrbscjbytes
familias
malware
menciono
previamente
cada
archivos
malware
disponibles
pertenecen
nueve
familias
o
clases
malware
informacion
en
cuentra
disponible
archivo
incluye
cada
muestra
clase
pertenece
nueve
familias
encuentran
ramnit
perteneciente
familia
tipo
troyanos
infecta
archivos
ejecutables
tales
exe
html
puede
esparcirse
facilmente
traves
dispositivos
removibles
ejemplo
memorias
usb
lollipop
tipo
adware
pup
potentially
unwanted
program
caracteriza
instalar
toolsbar
mostrar
publicidades
medio
ventanas
emergentes
kelihos
ver
tipo
botnet
normalmente
encuentra
relacionado
robo
bitcoins
envıo
spam
vundo
tipo
troyano
conocido
utilizar
popups
publicidad
progra
antivirus
maliciosos
simda
perteneciente
familia
backdoors
encargado
robar
informa
cion
usuarios
tales
nombres
usuario
contrasenas
certiﬁcados
capitulo
data
mining
generacion
dataset
tracur
familia
troyanos
capaz
redireccionar
busquedas
web
sitios
publicidad
fraudulenta
ademas
puede
descargar
ejecutar
archivos
ejemplo
malwares
kelihos
ver
botnet
relacionado
envıo
spam
masivo
obfuscatoracy
utiliza
tecnicas
ocultar
decarga
archivos
robo
informacion
gatak
perteneciente
familia
troyanos
encargara
reco
pilar
informacion
pc
esta
ejecutando
luego
enviarsela
hacker
analisis
seleccion
caracterısticas
mas
relevantes
archivos
descargados
siguiente
paso
consiste
teorizar
que
carac
terısticas
puede
llegar
ser
utiles
identiﬁcar
programa
similares
necesario
estudiar
estructura
cada
archivo
tamano
ﬁsonomıa
funcionamiento
instrucciones
ejecuta
uso
librerıas
continuacion
presentan
aquellas
caracterısticas
consideradas
mas
relevantes
librerıas
dll
dlls
dynamiclink
library
librerıas
enlace
dinamico
cargan
bajo
demanda
ejecucion
programa
archi
vos
correspondientes
almacenan
bajo
extension
dll
referencias
librerıas
pueden
resultar
interes
bajo
supuesto
mismo
tipo
malware
hace
uso
mismo
tipo
dlls
codigos
operacion
codigo
operacion
identiﬁca
tipo
instruccion
ejecutar
forma
similar
caso
anterior
presupone
miembros
misma
familia
malware
ejecutan
mismo
tipo
operaciones
secciones
codigo
asm
encuentra
dividido
distintas
secciones
header
text
rdata
modo
secciones
describen
terminos
generales
estructura
archivo
posible
miembros
misma
familia
compartan
misma
estructura
deben
ser
estudiadas
codigos
operacion
n
gramas
n
grama
secuencia
contigua
formada
n
items
alguna
muestra
texto
audio
numerica
cual
quier
fuente
este
investigando
tomando
codigos
operacion
anteriormente
mencionados
desea
determinar
miembros
misma
fa
milia
ejecutan
misma
secuencia
instrucciones
ngramas
codigos
operacion
extraccion
datos
tamanos
archivos
tamano
archivo
podrıa
ser
dato
representativo
clase
pertenece
dicho
malware
archivos
misma
clase
podrıan
tener
tamanos
similares
tamanos
archivos
comprimidos
igual
tamano
archivo
tamano
archivo
vez
comprimido
tambien
ratio
compresion
podrıa
resultar
dato
interes
snapshots
primeros
bytes
propone
estudiar
primer
kilo
byte
cada
archivo
proposito
determinar
malware
pertenecientes
misma
familia
comparten
cierta
ﬁsonomıa
extraccion
datos
vez
identiﬁcado
aquellos
aspectos
archivos
desean
ser
estudiados
siguiente
tarea
consiste
elaboracion
conjunto
procesos
permita
extraccion
datos
continuacion
describen
distintos
procesos
conforman
pipeline
tareas
minerıa
datos
ejecutadas
construccion
dataset
unico
partir
miles
muestras
malware
dlls
secciones
codigos
operacion
partiendo
supuesto
archivos
misma
familia
similares
cuanto
estructura
comportamiento
estudian
codigos
operacion
seccion
uso
dlls
ﬁn
determinar
veracidad
supuesto
modo
extraccion
atributos
diseno
implemento
pi
peline
procesos
objetivo
ﬁnal
determinar
cuales
features
mas
relevantes
cada
familia
ası
tambien
contabilizar
ocurrencias
atributos
relevantes
cada
muestras
disponibles
pipeline
puede
descomponerse
siguientes
pasos
calcular
cantidad
ocurrencias
cada
atributo
cada
muestras
determinar
atributos
mas
relevantes
cada
familias
crear
lista
unica
atributos
relevantes
total
familias
construir
tablacon
cantidad
ocurrencias
atributos
mas
rele
vantes
todas
muestras
conjunto
datos
capitulo
data
mining
generacion
dataset
procesamiento
archivos
asm
primer
paso
proceso
minerıa
features
consiste
tomar
archivos
asm
recorrerlos
lınea
lınea
busqueda
posible
ocurrencia
atributos
interes
cuales
totalizados
manera
construye
estructura
contiene
cada
archivo
asm
disponible
cantidad
veces
cada
feature
encontrado
ﬁgura
ilustra
primer
paso
proceso
figura
procesamiento
archivos
asm
resultado
proceso
diccionario
o
mapa
que
cada
muestra
totaliza
cantidad
cada
ocurrencias
encontradas
mismo
ilustra
continuacion
archivo
seccion
seccion
seccion
archivo
seccion
seccion
seccion
seccion
estructura
guardada
disco
utilizando
messagepack
provee
formato
eﬁciente
serializacion
mas
liviano
veloz
json
almacenar
infor
macion
manera
evita
tener
convertirla
representacion
tabular
puede
generar
archivo
redundancia
campos
mucha
dispersion
identiﬁcacion
dlls
logica
deteccion
dlls
debe
ser
capaz
detectar
cadena
dll
ser
sensible
mayusculas
minusculas
vez
debe
evitar
procesar
lıneas
correspondientes
comentarios
tal
ilustra
siguiente
imagen
httpsmsgpackorg
extraccion
datos
figura
extraccion
dlls
archivos
asm
identiﬁcacion
codigos
seccion
cada
lınea
comienza
preﬁjo
identiﬁca
tipo
seccion
lınea
cuestion
pertenece
codigo
siempre
seguido
dos
puntos
modo
extraer
codigo
seccion
tan
simple
obtener
cadena
izquierda
primer
dos
puntos
figura
extraccion
codigos
seccion
archivos
asm
identiﬁcacion
codigos
operacion
asume
codigo
operacion
primer
palabra
lınea
cuanto
trate
comentario
figura
extraccion
codigos
operacion
archivos
asm
totalizacion
ocurrencias
calculo
proporciones
vez
procesados
archivos
asm
obtenido
total
occurrencias
cada
feature
archivo
debe
determinar
cuales
features
carac
terizan
realmente
cada
familias
solucion
simple
problema
podrıa
ser
totalizar
ocurrencias
cada
atributo
por
familia
luego
quedar
aquellos
produjeron
cuentas
mas
altas
embargo
enfoque
puede
llevar
problemas
inconsistencias
presencia
valores
anomalos
graﬁcar
situacion
propone
siguiente
tabla
presenta
cantidad
lıneas
cada
seccion
encontrada
cada
siete
archivos
ejemplo
capitulo
data
mining
generacion
dataset
seccion
seccion
seccion
seccion
seccion
seccion
archivo
archivo
archivo
archivo
archivo
archivo
archivo
total
cuadro
ejemplo
totalizacion
secciones
usando
sumas
ocurrencias
rapida
inspeccion
tabla
anterior
podemos
observar
siete
ar
chivos
contienen
numero
elevado
lıneas
pertenecientes
seccion
seccion
seccion
tambien
observan
valores
atıpicos
seccion
archivo
sec
cion
archivo
suponiendo
objetivo
obtener
cuatro
secciones
mas
relevantes
basandonos
cantidad
ocurrencias
estas
serıan
seccion
seccion
seccion
seccion
evidencia
dos
tipos
problemas
sensibilidad
valores
atıpicos
seccion
seccion
aparecen
tan
solo
archivo
cada
uno
cantidad
extremadamente
alta
valores
inusuales
hacen
identiﬁcados
features
mas
importantes
omision
features
relevantes
corolario
sensibilidad
valores
atıpi
cos
mencionada
punto
anterior
atributos
deberıan
ser
capturados
seccion
desplazados
identiﬁcados
importantes
pa
ra
correspondiente
familia
solucionar
dos
problemas
necesario
comprender
hace
mas
relevante
feature
cantidad
ocurrencias
sino
que
proporcion
cantidades
representan
total
ocurrencias
cada
archivo
ası
puede
expresar
tabla
utilizando
proporciones
siguiente
manera
extraccion
datos
seccion
seccion
seccion
seccion
seccion
seccion
archivo
archivo
archivo
archivo
archivo
archivo
archivo
total
cuadro
ejemplo
totalizacion
secciones
usando
proporcio
nes
puede
observarse
uso
proporciones
produce
resultados
capturan
mejor
manera
relevancia
cada
atributo
establecido
estrategia
mediante
determinaran
atribu
tos
mas
importantes
siguiente
paso
pipeline
consiste
consumir
archivo
generado
paso
anterior
features
totalizados
archivo
convertir
proporciones
acumular
valores
familia
figura
calculo
totalizacion
ocurrencias
modo
proceso
genera
dos
archivos
salida
analogo
resultado
proceso
anterior
cantidades
ocurrencias
expresadas
propor
ciones
similar
contenido
cuadro
archivo
sera
gran
utilidad
ultimo
paso
proceso
extraccion
atributos
segundo
archivo
contie
ne
totalizacion
proporciones
anteriormente
mencionadas
cada
nueve
familias
malware
disponen
archivo
sera
utilizado
siguiente
paso
proceso
determinacion
features
mas
relevantes
vez
ejecutado
paso
anterior
dispone
proporciones
ocurrencias
cada
feature
archivo
modo
posible
totalizar
va
lores
familia
permite
determinar
cuales
atributos
mas
relevantes
capitulo
data
mining
generacion
dataset
cada
clases
malware
disponible
siguiente
ﬁgura
presenta
diagrama
proceso
obtencion
atributos
mas
relevantes
cada
familias
malware
disponibles
figura
determinacion
features
mas
importante
cada
familia
dada
gran
cantidad
atributos
disponible
necesario
poder
reducir
numero
sacriﬁcar
demasiada
performance
modelos
machine
learning
ello
debe
escoger
punto
corte
adecuado
tarea
puede
realizarse
facilidad
vuelcan
cantidades
cada
atributo
graﬁco
barras
adi
cionalmente
cabe
destacar
elegira
mismo
numero
features
intencion
producir
conjunto
datos
balanceado
imagenes
permiten
visualizar
atributos
mas
relevantes
cada
clase
comenzando
utilizacion
librerıas
dll
podemos
distinguir
rapida
mente
cada
clase
podemos
observar
que
independiente
orden
generalmente
primeras
cinco
librerıas
son
kerneldll
modulo
kernel
windows
que
arranca
sistema
cargada
area
protegida
memoria
pueda
ser
modiﬁca
da
ningun
usuario
proceso
userdll
librerıa
contiene
funciones
api
windows
ver
interfaz
usuario
advapidll
provee
api
funciones
relacionadas
llamadas
re
gistry
sistema
funciones
seguridad
msvcrtdll
modulo
parte
librerıa
microsoft
c
runtime
contiene
fun
ciones
estandar
printf
memcpy
cos
gdidll
librerıa
funciones
windows
gdi
graphical
device
inter
face
asiste
sistema
ventanas
creacion
objetos
bidimensio
nales
extraccion
datos
figura
top
dlls
mas
relevantes
cada
clase
malware
similar
resultados
observados
uso
librerıas
dll
codigos
operaciones
podemos
identiﬁcar
cinco
valores
mas
recurrentes
primeros
puestos
son
capitulo
data
mining
generacion
dataset
mov
operacion
que
general
toma
dos
operandos
copia
valor
otro
push
funcion
recibe
lista
registros
apila
stack
orden
descendiente
call
permite
invocacion
subrutina
etiquetada
parametro
dd
operacion
usa
declarar
dato
cuatro
bytes
db
operacion
utilizada
declaracion
dato
byte
extraccion
datos
figura
top
codigos
operacion
mas
relevantes
cada
clase
malware
capitulo
data
mining
generacion
dataset
figura
top
codigos
seccion
mas
relevantes
cada
clase
malware
estudiando
mas
cerca
codigos
seccion
obtenidos
distingue
que
mayorıa
casos
tres
codigos
mas
frecuentes
son
extraccion
datos
data
seccion
dedicada
inicializacion
datos
variables
rdata
similar
data
distincion
ser
solo
lectura
text
seccion
contiene
instrucciones
consolidacion
resultados
determinado
atributos
mas
importantes
cada
fa
milias
unico
paso
restante
consiste
construir
lista
unica
atributos
repeticiones
lista
utilizada
conjunto
archivo
generado
segun
do
paso
correspondiente
proporciones
cada
feature
cada
archivo
como
describe
ﬁgura
elaboracion
dataset
contiene
cada
archivo
proporcion
ocurrencias
cada
atributos
relevantes
cualquiera
familia
ﬁgura
representa
ultimo
paso
proceso
data
mining
figura
obtencion
proporciones
ocurrencias
relevantes
archivo
resumen
obtencion
features
mas
importantes
dlls
codigos
operacion
seccion
trabajo
extenso
laborioso
implico
combinacion
dis
tintas
tareas
requirio
primero
estudio
estructura
archivos
asm
poder
determinar
como
localizar
extraer
datos
deseados
luego
procedio
construccion
ejecucion
distintos
algoritmos
minerıa
concreta
da
tos
sortearse
inconvenientes
relacionados
principalmente
problemas
encoding
archivos
lado
lugar
elaboracion
herramientas
validar
informacion
generada
traves
graﬁcos
tablas
dar
soporte
toma
decisiones
finalmente
escoger
estra
tegia
identiﬁcar
seleccionar
atributos
mas
relevantes
cada
familias
malware
vision
global
todas
tareas
involucradas
proceso
ofrece
ﬁgura
capitulo
data
mining
generacion
dataset
figura
obtencion
proporciones
ocurrencias
relevantes
archivo
dlls
codigos
operacion
seccion
snapshots
archivos
asm
trabajo
realizado
subseccion
anterior
implica
analisis
minucioso
cada
lına
archivos
asm
extraer
informacion
interes
punto
embargo
enfoque
centra
estudio
ﬁsonomıa
cada
archivos
forma
similar
foto
identiﬁcacion
documento
pasaporte
propone
sacar
foto
escala
grises
primeros
bytes
cada
archivo
asm
utilizar
imagenes
x
bytes
entrenar
red
neuronal
capaz
de
cada
muestra
analizada
asignar
probabilidad
misma
pertenezca
cada
familias
extraccion
datos
captura
snapshots
primer
paso
minerıa
datos
punto
involucro
generacion
snapshots
partir
primeros
bytes
cada
archivo
asm
modo
utilizo
librerıa
python
imageio
creacion
imagenes
x
bytes
escalas
grises
ﬁgura
presenta
cinco
muestras
cada
familia
una
ﬁla
snapshots
presentan
escala
tamano
original
mejor
visualizacion
figura
snapshots
x
bytes
cada
familia
malware
httpspypiorgprojectimageio
capitulo
data
mining
generacion
dataset
entrenamiento
red
neuronal
vez
generada
totalidad
imagenes
procedio
construccion
red
neuronal
utilizando
tensorflow
objetivo
proceso
obte
ner
estimacion
mas
precisa
posible
sino
poder
observar
grandes
rasgos
similitud
archivos
pertenecientes
misma
clase
ser
capaz
poder
realizar
estimaciones
cada
muestras
red
construida
utilizando
kfold
tecnica
kfold
permite
dividir
conjunto
datos
k
partes
iguales
conocidas
folds
splits
ejecutar
k
corridas
cada
corri
da
toma
split
distinto
conjunto
test
restantes
conjunto
datos
entrenar
modelo
construccion
red
utilizo
k
figura
kfold
utilizado
clasiﬁcar
snapshots
vez
ejecutada
red
obtuvo
precision
alrededor
produ
ciendo
resultados
siguiente
formato
figura
muestra
resultados
red
neuronal
cla
siﬁcar
snapshots
tamanos
archivos
compression
rate
continuando
estudio
muestras
punto
vista
ﬁso
nomıa
procedio
determinar
tamano
archivo
asm
tambien
archivo
bytes
cada
malware
conforma
conjunto
datos
adicionalmente
cal
cularon
tamanos
ambos
archivos
vez
comprimidos
mediante
gzip
gzip
gnu
zip
tecnica
compresion
estandar
extraccion
datos
partiendo
supuesto
archivos
misma
familia
deben
tener
tamano
similar
minerıa
atributos
realiza
objetivo
determinar
si
efecto
distintos
tamanos
compression
rate
pueden
ser
utiles
identiﬁcacion
cada
malware
dentro
correspondiente
familia
ası
construyo
script
que
vez
ejecutado
produjo
archivo
for
mato
ilustra
siguiente
imagen
figura
extraccion
tamanos
archivos
tamano
ar
chivos
comprimidos
ngramas
ultimo
conjunto
atributos
extraıdo
archivos
malware
trata
gramas
importantes
formados
ocurrencias
codigos
operacion
mas
relevantes
fue
quizas
tarea
mas
extensa
todas
obtener
ngramas
partir
secuencia
valores
signiﬁca
recorrer
misma
ventana
tamano
n
desplazandose
posicion
vez
registrando
valor
observado
objetivo
construir
ngramas
analizar
operaciones
ejecutadas
pero
lugar
enfocarnos
individualmente
centramos
estudiar
secuen
cias
instrucciones
ejecutan
juntas
pretende
determinar
miembros
misma
familia
malware
tienden
ejecutar
misma
serie
operaciones
importante
tener
cuenta
trabaja
unicamente
codigos
operaciones
mas
relevantes
minimizar
numero
combinaciones
posibles
modo
trabajo
ser
realizado
puede
dividir
dos
tareas
lado
construccion
ngramas
basados
codigos
operacion
mas
importantes
lado
debe
realizar
identiﬁcacion
obtencion
ngramas
mas
relevantes
cada
familia
primer
tarea
obtencion
ngramas
hace
base
codigos
operacion
mas
relevantes
mencionado
subseccion
ası
archivos
asm
deben
ser
recorridos
nuevamente
armar
ngramas
diagrama
graﬁca
proceso
capitulo
data
mining
generacion
dataset
figura
proceso
extraccion
ngramas
vez
extraıdos
ngramas
procede
ﬁltrado
aquellos
mas
relevantes
forma
similar
trabajo
realizado
features
dlls
codigos
seccion
operacion
continuacion
presentan
imagenes
diez
gramas
mas
relevantes
cabe
destacar
decision
utilizar
solamente
codigo
operacion
mas
relevantes
tomo
intencion
reducir
numeros
combinaciones
posi
bles
aun
ası
obtuvieron
gran
numero
ngramas
distintos
ejemplo
familia
posee
gramas
distintos
extraccion
datos
figura
top
gramas
mas
relevantes
cada
clase
malware
capitulo
data
mining
generacion
dataset
figura
top
gramas
mas
relevantes
cada
clase
malware
extraccion
datos
figura
top
gramas
mas
relevantes
cada
clase
malware
capitulo
data
mining
generacion
dataset
detalles
tecnicos
dada
cantidad
atributos
extraer
diversidad
mismos
aspecto
fundamental
hora
implementar
algoritmos
data
mining
tratar
logar
mejor
abstraccion
posible
minimizar
repeticion
codigo
ende
construccion
procesos
mencionados
seccion
anterior
punto
central
implementacion
dos
clases
con
correspondientes
subclases
categoryfeatureprocessor
clase
responsable
de
partir
nombre
atributo
dll
numero
categorıa
realizar
extrac
cion
feature
correspondiente
archivos
familia
gracias
patron
diseno
template
method
subclases
concretas
proveen
imple
mentacion
necesaria
obtener
informacion
segun
atributo
este
analizando
lineparser
mismo
tipo
diseno
mencionado
punto
anterior
aplico
abstraer
proceso
analisis
lınea
individual
archivo
busqueda
informacion
interes
codigo
operacion
seccion
referencia
librerıa
dll
imagen
ofrece
diagrama
clases
puede
observar
mejor
detalle
clases
relacion
figura
extraccion
features
archivos
asm
conclusion
cabe
recordar
estudio
referencia
librerıas
codigos
seccion
operacion
construccion
ngramas
clasiﬁcacion
snapshots
requirieron
procesos
adicionales
algoritmos
abordados
discutieron
cada
features
conclusion
proceso
data
mining
tarea
compleja
demandante
requirio
considerable
inversion
tiempo
comprender
naturaleza
estructura
archivos
malware
original
poder
empezar
trabajar
luego
ne
cesaria
elaboracion
diversos
tipos
algoritmos
capaz
extraer
informacion
correspondiente
numero
diverso
atributos
ası
tambien
idear
estrategias
calculo
almacenado
resultados
intermedio
adi
cionalmente
debieron
crear
herramientas
apoyo
permitieran
validar
datos
extraıdos
correctos
ası
tambien
graﬁcar
informacion
obte
nida
poder
determinar
relevancias
puntos
corte
resultado
proceso
archivo
csv
atributos
servira
dataset
algoritmos
machine
learning
descriptos
proximo
capıtulo
capitulo
analisis
exploratorio
preprocesamiento
datos
proceso
data
mining
ﬁnalizo
construccion
dataset
producto
extraccion
distintos
atributos
identiﬁcados
interes
analisis
clasiﬁcacion
malware
embargo
archivo
csv
resultante
esta
listo
aun
ser
utilizado
entrenar
modelos
machine
learning
sino
necesario
llevar
cabo
numero
tareas
adicionales
mejorar
calidad
mismo
traves
analisis
exploratorio
datos
eda
siglas
ingles
obtendra
mejor
entendimiento
datos
recolectados
mediante
metricas
graﬁcas
vez
analisis
permitira
tratamiento
datos
nulos
datos
faltantes
determinar
importancia
variables
proceder
seleccion
extraccion
estandarizado
escalado
atributos
hizo
uso
extensivo
distintas
librerıa
python
pandas
matplotlib
scikitlearn
cabe
destacar
capıtulo
ofrecera
conceptos
teoricos
adicionales
cubiertos
marco
teorico
ser
demasiados
especıﬁcos
trabajo
realizado
seccion
estructura
contenido
dataset
comenzar
cualquier
tipo
analisis
datos
conforman
dataset
necesario
estudiar
propia
estructura
archivo
permite
adquirir
cierta
dimension
volumen
datos
trabajara
utilizando
pandas
cargo
archivo
csv
dataframe
y
ası
observo
dataset
resultante
posee
ﬁlas
correspondientes
cada
muestras
disponibles
columnas
cada
atributos
extraıdos
enfocandonos
columnas
observan
httpspandaspydataorg
httpsmatplotliborg
httpsscikitlearnorgstableindexhtml
capitulo
analisis
exploratorio
preprocesamiento
datos
codigos
seccion
header
text
idata
rdata
data
rsrc
bss
gnu
deb
tls
code
data
bss
gap
data
xref
crt
seg
seg
code
zenc
seg
yogmamm
iuagwws
qmoyiu
acggagg
tixt
agauixa
code
rdata
seg
seg
icode
unisec
hwa
oinf
dwr
oj
rata
tls
pav
upx
xdata
hc
c
bas
librerıas
dll
kernel
user
advapi
msvcrt
ole
oleaut
gdi
shlwapi
version
urlmon
shell
mlang
wininet
mscoree
secur
comdlg
libgcj
s
setupapi
ntdll
uxtheme
crypt
ws
apphelp
tapi
msvcp
dsound
mscms
msasn
dpnet
ntmarta
opengl
ntshrui
usp
clbcatq
rsaenh
forkernel
foruser
loadperf
msvbvm
codigos
operacion
proc
dword
push
mov
sub
lea
call
pop
add
align
test
jz
xor
cmp
endp
db
jmp
retn
dd
imul
mul
gramas
dword
dword
push
push
push
mov
mov
push
push
lea
mov
call
call
mov
mov
mov
lea
push
push
call
call
add
mov
cmp
cmp
mov
call
pop
pop
pop
proc
mov
mov
add
pop
retn
align
proc
dd
dd
dd
db
jmp
db
add
mov
retn
endp
sub
mov
db
dd
db
db
add
pop
mov
imul
mov
sub
jmp
dd
pop
push
jmp
jmp
db
jmp
gramas
dword
dword
dword
mov
push
push
push
lea
push
push
push
call
push
call
add
push
push
push
mov
mov
push
push
call
mov
push
push
mov
push
mov
push
mov
push
mov
push
mov
mov
mov
mov
mov
mov
mov
add
push
call
pop
mov
push
call
dd
dd
dd
dd
dd
db
mov
add
mov
push
call
push
call
pop
retn
sub
mov
mov
mov
mov
call
lea
push
push
db
dd
db
call
add
pop
proc
mov
push
align
proc
mov
db
dd
dd
push
mov
sub
mov
sub
mov
add
mov
mov
db
db
db
mov
mov
sub
call
pop
push
mov
sub
lea
jmp
jmp
jmp
db
jmp
db
dd
db
jmp
jmp
db
dd
add
pop
push
jmp
dd
db
gramas
dword
dword
dword
dword
lea
push
lea
push
push
lea
push
call
push
push
push
push
push
mov
push
mov
mov
push
mov
mov
mov
mov
mov
add
mov
push
mov
push
pop
retn
align
proc
push
mov
push
push
push
mov
call
mov
dd
dd
dd
dd
dd
dd
dd
db
mov
mov
mov
mov
proc
dword
dword
dword
push
push
push
mov
push
push
push
call
push
push
call
mov
call
mov
mov
mov
lea
push
push
call
push
lea
push
push
push
call
add
pop
proc
mov
push
mov
align
proc
mov
push
mov
push
push
push
mov
push
mov
sub
mov
add
mov
mov
push
push
call
add
push
push
call
pop
proc
mov
push
push
db
db
db
db
mov
mov
add
mov
mov
mov
sub
mov
mov
sub
mov
mov
add
mov
mov
mov
mov
mov
mov
sub
push
call
pop
push
call
pop
push
call
jmp
jmp
jmp
jmp
push
mov
sub
lea
dd
db
jmp
db
db
jmp
db
dd
jmp
db
dd
dd
call
add
pop
push
add
pop
push
push
jmp
db
dd
db
dd
dd
db
jmp
probabilidades
columnas
corresponden
clasiﬁcacion
snaps
hots
primeros
bytes
cada
archivo
asm
valores
nulos
datos
faltantes
tamanos
archivo
columnas
contienen
tamano
cada
archivo
asm
bytes
versiones
comprimidas
considerando
curvas
presentadas
secciones
cantidad
atributos
cada
feature
parece
ser
razonable
dos
casos
quizas
resulten
interes
bajo
numero
codigos
operacion
numero
relativamente
alto
codigos
seccion
bien
veintitres
codigos
operacion
pueden
parecer
numero
relativamente
bajo
compara
features
realidad
cantidad
resulta
razonable
dado
cantidad
codigos
operacion
x
varıa
ochenta
cien
segun
version
cuanto
codigos
seccion
interesante
analizar
graﬁcos
barras
ﬁgura
puede
observarse
que
mayorıa
clases
valores
relativamente
pequenos
luego
primeros
cuatro
cinco
codigos
ademas
mencionado
anteriormente
identiﬁcan
tres
cuatro
codigos
encabezando
graﬁcas
todas
familias
contexto
obtener
total
treinta
nueve
codigos
distintos
habla
como
cada
familia
hace
uso
secciones
distintas
resto
valores
nulos
datos
faltantes
presencia
datos
faltantes
nulos
dataset
suele
tener
impacto
nega
tivo
performance
modelos
entrenen
base
el
motivo
primera
tarea
suele
llevarse
cabo
preprocesamiento
datos
busqueda
identiﬁcacion
valores
nulos
faltantes
correspondiente
correc
cion
describio
seccion
existen
diversas
tecnicas
tratamien
to
datos
nulos
seleccionar
mas
adecuada
imperativo
comprender
origen
valores
faltantes
analisis
valores
nulos
gracias
distintas
funciones
pandas
pudo
determinarse
naturaleza
valores
nulos
debıan
dos
razones
archivos
que
problemas
encoding
integridad
pudieron
ser
analiza
dos
ende
ﬁlas
practicamente
vacıas
salvo
columnas
correspondientes
tamanos
archivo
total
identiﬁcaron
mas
muestras
capitulo
analisis
exploratorio
preprocesamiento
datos
archivos
registraban
ocurrencias
atributos
resultaron
relevan
tes
familias
problema
debe
casos
modo
obtuvieron
atributos
mas
relevantes
relacionados
codigos
operacion
seccion
uso
librerıas
dll
ngramas
ilustrar
situacion
puede
imaginar
que
traba
jando
dlls
identiﬁcaron
librerıas
dll
dll
mas
relevantes
familia
ramnit
librerıas
dll
dll
mas
importantes
familia
lollipop
solo
analizando
dos
familias
conjunto
atributos
relevantes
estarıa
conformado
dll
dll
dll
adicionalmente
podrıa
agregarse
escenario
ninguna
muestra
familia
ramnit
hace
uso
dll
ejecutar
consolidacion
resultados
descripta
subsec
cion
obtendrıa
dataset
columna
correspondiente
dll
estarıa
vacıa
muestras
correspondientes
familia
ramnit
proceder
resolucion
valores
nulos
vale
pena
mencionar
estudio
valores
faltantes
brindo
mayor
entendimiento
respecto
relevancia
real
cada
atributos
ejemplo
librerıas
kernel
gdi
ole
utilizadas
mayorıa
archivos
unicamente
hacen
secciones
header
rdata
text
aparecen
archivos
forma
analoga
atributos
mayor
cantidad
valores
faltantes
corresponden
casos
codigos
seccion
tales
oj
oinf
unisec
valores
nulos
habla
como
secciones
bien
pueden
haber
resultado
relevantes
familias
realmente
utilizadas
resto
resolucion
valores
nulos
describio
subseccion
anterior
datos
faltantes
dos
orıge
nes
distintos
resolucion
primer
problema
archivos
corruptos
alternativa
mas
eliminar
ﬁlas
correspondientes
mientras
segundo
problema
columnas
mediciones
completaron
celdas
cero
dado
que
contexto
valor
nulo
representa
cero
ocurrencias
distribucion
valores
aplicado
estrategia
solucionar
problema
campos
nu
los
prosigue
estudiar
distribucion
valores
cada
feature
nuevamen
te
podemos
utilizar
funcion
pandas
datos
obtener
mınimos
maximos
cada
columna
ası
valor
medio
desviacion
estandar
medicion
distintos
cuartiles
distribucion
valores
ejempliﬁcar
informacion
obtenida
seleccionan
tres
atributos
mas
im
portantes
de
acuerdo
analisis
realizado
posteriormente
seccion
estudio
atributo
mean
std
min
max
header
proc
mov
push
mov
add
pop
cuadro
estadısticas
tres
atributos
mas
importantes
partir
tabla
anterior
pueden
realizarse
diversas
observaciones
basandonos
columna
max
ninguno
tres
atributos
utilizado
manera
desproporcionada
casos
menos
muestras
presentan
ocurrencias
atributos
basandose
desviacion
std
puede
considerarse
header
presenta
valores
compactados
alrededor
media
mediante
dos
casos
estos
encuentran
mas
dispersos
continuacion
incluyen
imagenes
correspondientes
graﬁcos
densidades
cada
tres
atributos
figura
kde
plot
header
capitulo
analisis
exploratorio
preprocesamiento
datos
figura
kde
plot
ngrama
proc
mov
push
mov
figura
kde
plot
ngrama
add
pop
lado
tambien
encontraron
archivos
cumpliendo
alguna
con
diciones
compuestos
enteramente
misma
seccion
data
seg
utilizar
solo
unica
librerıa
kerneldll
msvbvmdll
ejecutar
misma
instruccion
dd
db
ejecutar
misma
secuencia
instrucciones
grama
push
push
push
call
finalmente
incluye
graﬁco
densidad
valores
observados
seccion
seg
resulta
curioso
amplia
mayorıa
muestras
importancia
variables
utilizan
seccion
absoluto
embargo
hacen
hacen
uso
ninguna
otra
figura
kde
plot
seccion
seg
importancia
variables
dataset
valores
nulos
resueltos
procedio
determinar
im
portancia
variables
hacer
estudio
importancia
variables
gran
utilidad
permite
comprender
que
atributos
mas
relevantes
modelo
que
vez
aporta
beneﬁcios
adicionales
tales
como
veriﬁcar
correctitud
modelo
evaluar
posibilidades
mejoras
cen
trar
enfoque
aquellos
atributos
mas
importante
modelo
acortar
tiempos
entrenamiento
sacriﬁcar
demasiada
performance
seleccionar
atributos
mas
relevantes
descartar
aquellos
cuya
incidencia
despreciable
mayor
interpretabilidad
modelo
tener
sacriﬁcar
necesariamente
demasiada
performance
hace
seleccion
atributos
adecuada
llevar
adelante
proceso
utilizo
algoritmo
clasiﬁcacion
random
forest
debe
recordar
random
forest
ensamble
decision
trees
utiliza
variacion
metodo
bagging
arboles
independientes
entrenados
utilizando
mismo
conjunto
datos
normalmente
forest
puede
contener
varios
cientos
arboles
capitulo
analisis
exploratorio
preprocesamiento
datos
utilizando
librerıa
scikitlearn
posible
establecer
importancia
atributos
random
forest
traves
dos
metodos
distintos
metodo
de
fecto
computar
importancia
variables
basa
mecanismo
decremento
mınimo
impureza
impuridad
gini
impuridad
gini
me
dida
determina
cual
probabilidad
nueva
observacion
incorrectamente
clasiﬁcada
arbol
construido
decision
acerca
que
variable
utilizar
separar
cada
nodo
emplea
calculo
impuridad
gini
cada
variable
suma
decrementos
gini
cada
arbol
bosque
acumulada
cada
vez
variable
elegida
separar
nodo
suma
luego
dividida
cantidad
arboles
bosque
determinar
prome
dio
metodo
cuenta
ventaja
ser
facil
implementar
calculo
rapido
contrario
dado
estadısticas
computadas
derivan
modelo
entrenamiento
estas
podrıan
reﬂejar
habilidad
feature
ser
util
realizar
predicciones
generalicen
conjunto
prueba
metodo
determinar
importancia
variables
quizas
mas
utilizado
consiste
basicamente
observar
que
decrementa
precision
modelo
variable
excluida
cada
arbol
propias
observa
ciones
outofbag
oob
cuales
seran
utilizados
construccion
observaciones
seran
utilizadas
calcular
importancia
variable
especıﬁ
ca
primero
precision
prediccion
observaciones
oob
medida
luego
valores
variables
observaciones
oob
mezcladas
aleatoriamente
mientras
variables
mantienen
igual
ultimo
decremento
precision
prediccion
observaciones
mezcladas
medido
decremento
mınimo
precision
traves
arboles
reportado
ventaja
metodo
puede
ser
aplicado
cualquier
modelo
resulta
bastante
eﬁciente
tecnica
bastante
conﬁable
desventaja
resulta
mu
cho
mas
costoso
computacionalmente
metodo
defecto
tambien
podrıa
sobreestimar
importancia
predictor
correlacionado
investigacion
utilizo
metodo
defecto
calculo
impor
tancia
variables
ser
menos
costo
computacional
tiene
imagen
ilustra
resultado
arrojo
proceso
indicado
anteriormente
dicho
graﬁco
puede
observarse
totalidad
variables
ordenadas
ma
yor
menor
relevancia
como
valores
ﬁnal
curva
realmente
pequenos
httpsscikitlearnorg
seleccion
variables
figura
importancia
variables
seleccion
variables
determinar
importancia
variables
solo
puede
ayudar
lograr
mejor
interpretacion
datos
sino
tambien
permite
establecer
ranking
seleccionar
aquellos
features
realmente
importantes
modelo
prediccion
contexto
utilizando
librerıa
scikit
learn
seleccion
variables
junto
resultado
obtenido
paso
anterior
utilizo
objeto
selectfrommodel
provisto
mencionada
librerıa
scikit
learn
objeto
seleccionara
to
dos
aquellos
features
cuyo
valor
importancia
mayor
umbral
caso
media
importancia
features
resultado
aplicar
proceso
permitio
reducir
notablemente
comple
jidad
dataset
cual
paso
tener
columnas
tan
solo
cuyas
columnas
componen
de
codigos
seccion
librerıas
dll
httpsscikitlearnorgstablemodulesgeneratedsklearnfeature_selection
selectfrommodelhtml
capitulo
analisis
exploratorio
preprocesamiento
datos
codigos
operaciones
gramas
gramas
gramas
columnas
correspondientes
distintos
tamanos
archivo
estandarizacion
atributos
menciono
marco
teorico
investigacion
muchas
veces
trabaja
datos
magnitudes
resultan
diferentes
sı
puede
ser
problema
estimadores
empleados
algoritmos
machine
learning
sensibles
estandarizado
atributos
podrıan
tener
com
portamiento
errado
valores
mas
menos
similares
ejemplo
elementos
utilizados
funcion
objetivo
algoritmo
aprendizaje
tales
rbf
kernel
support
vector
machine
regularizaciones
l
l
modelos
lineales
asumen
features
estan
centrados
alrededor
varianza
mismo
orden
feature
posee
varianza
cuyo
orden
magnitud
superior
otros
este
probablemente
domine
funcion
objetivo
haga
estimador
posible
aprender
features
correctamente
dependiendo
problema
quiere
abordar
pueden
utilizar
diferentes
tecnicas
estandarizacion
normalizacion
datos
resulten
utiles
hora
poner
marcha
algoritmos
machine
learning
desean
presente
investigacion
realizo
escalado
estandar
realizar
extracion
atributos
utilizando
kernel
pca
escalado
estandar
funciona
bien
correlacion
traves
calculo
correlacion
pearson
calcula
coeﬁciente
establece
medida
dos
variables
correlacionan
pudo
construir
graﬁca
puntos
mas
claros
indicadores
alta
correlacion
pares
mientras
colores
oscuros
indicadores
correlacion
leve
ausencia
misma
graﬁco
desprenden
correlaciones
obvias
tales
n
gramas
ngramas
similares
dd
dd
dd
dd
dd
valor
tam
bien
percibieron
correlaciones
hablan
estructura
archivos
ejemplo
seccion
header
presenta
correlacion
seccion
idata
extraccion
atributos
kernel
pca
lado
correlaciones
esperables
dado
funcionamiento
len
guaje
assembler
ejemplo
operacion
mov
llamado
subrutinas
correlacion
operaciones
relacionadas
pasaje
parame
tros
push
pop
figura
correlacion
pearson
extraccion
atributos
kernel
pca
principal
component
analysis
pca
herramienta
utiliza
reducir
dimensionalidad
datos
perder
informacion
pca
reduce
dimension
hallando
combinaciones
lineales
ortogonales
componentes
principales
variables
originales
varianza
mas
alta
primer
componente
principal
captura
mayor
parte
varianza
datos
segundo
componente
principal
ortogonal
primer
componente
captura
varianza
restante
dejada
capitulo
analisis
exploratorio
preprocesamiento
datos
primer
componente
principal
ası
sucesivamente
existen
tantos
componen
tes
principales
numero
variables
original
componentes
principales
correlacion
encuentran
ordenados
manera
primeros
com
ponentes
principales
expliquen
mayorıa
varianza
datos
originales
dado
pca
metodo
lineal
solo
puede
ser
aplicado
conjuntos
datos
linealmente
separables
resultara
buena
herramienta
siempre
cuan
do
datos
cumplan
premisa
kernel
pca
cambio
utiliza
funcion
kernel
proyectar
dataset
espacio
dimensional
mas
alto
linealmen
separable
manera
similar
hace
support
vector
machine
presente
investigacion
analisis
componentes
principales
llevo
cabo
utilizando
herramienta
kernel
pca
graﬁco
puede
observar
resultado
aplicar
dicha
herramienta
figura
analisis
componentes
kernel
pca
observar
graﬁco
posible
determinar
como
numero
componen
tes
superior
logra
explicar
gran
porcentaje
varianza
modelo
practica
numero
componentes
seleccionar
depende
que
tanta
varianza
desea
kpca
explique
investigacion
ﬁjo
valor
tomarse
primeros
componentes
principales
resumen
realizacion
pasos
previamente
descriptos
permitio
solo
reducir
drasticamente
dimensionalidad
conjunto
datos
sino
tambien
eli
minar
muestras
posible
trabajar
dado
archivos
resumen
origen
encontraban
danados
tambien
logro
mejor
entendimiento
pro
blema
quiere
modelar
algoritmos
machine
learning
ademas
rellenar
datos
faltantes
datos
nulos
ceros
ası
tambien
estandari
zacion
logro
llevar
dataset
mas
consistente
completo
capitulo
clasiﬁcacion
malware
capıtulo
anterior
describieron
tareas
realizadas
depuracion
selecion
tranformacion
atributos
ası
obtuvo
conjunto
datos
mas
con
sistente
cada
variables
involucradas
realmente
importantes
modelo
modo
puede
dar
comienzo
construccion
elabora
cion
diversos
algoritmos
machine
learning
algoritmos
permitiran
realizar
clasiﬁcaciones
distintas
familias
malware
partir
resultados
arrojen
podran
realizar
comparaciones
establecer
conclusiones
algoritmos
clasiﬁcacion
menciono
marco
teorico
investigacion
existen
varios
modelos
pueden
ser
utilizados
problemas
clasiﬁcacion
seleccionaron
siguientes
knearest
neighbors
random
forest
xgboost
red
neuronal
seran
ejecutados
tomando
datos
entrada
dataset
prepro
cesado
resultados
seran
luego
evaluados
mediante
valor
correspondiente
precision
gracias
libreria
scikitlearn
matriz
confusion
graﬁca
roc
receiver
operating
characteristic
knearest
neighbors
primera
instancia
realizo
implementacion
algoritmo
knearest
neighbors
explicado
marco
teorico
knearest
neighbors
knn
clasiﬁca
cada
punto
mediante
analisis
vecinos
mas
cercanos
dentro
capitulo
clasiﬁcacion
malware
conjunto
entrenamiento
punto
asignado
clase
mas
comun
en
contrada
dichos
vecinos
algoritmo
parametrico
realiza
asunciones
acerca
como
datos
estan
distribuidos
implementacion
implementacion
knearest
neighbors
llevaron
cabo
siguientes
pasos
leen
archivos
contienen
datos
preprocesados
explicados
ante
riormente
archivo
contiene
etiquetas
utilizando
librerıa
scikitlearn
separa
conjunto
datos
training
testing
proporcion
o
respectivamente
crean
dos
objetos
clasiﬁcador
kneighborsclassifier
correspondiente
analisis
componentes
vecindario
denominada
neighborhoodcomponent
ambas
pertenecientes
librerıa
scikitlearn
neighborhood
component
analy
sis
objetivo
encontrar
transormacion
lineal
maximice
precision
clasiﬁcacion
vecino
mas
cercano
estocastico
conjunto
entrenamiento
kneighborsclassifier
valor
k
establecido
valor
defecto
neighborhoodcomponentsanalysis
tambien
valores
defecto
colocados
dentro
estructura
llamada
pipeline
proposito
pipeline
ensamblar
varios
pasos
puedan
ser
vali
dados
juntos
utilizando
crossvalidation
permitiendo
ası
conﬁguracion
diferentes
parametros
ﬁnalizado
paso
anterior
procede
realizar
fit
ajustando
mo
delo
acuerdo
datos
entrenamiento
provistos
paso
ﬁnal
sera
prediccion
sera
realizada
conjunto
prueba
permitira
luego
proyectar
resultados
matriz
confusion
precision
logrado
metricas
evaluacion
caso
knearest
neighbors
gracias
utilizacion
analisis
com
ponentes
vecindario
logrado
precision
prediccion
haberla
utilizado
debe
recordar
precision
metricas
mas
comunes
utilizadas
medir
performance
modelo
cla
siﬁcacion
esta
permitira
identiﬁcar
rapidamente
proporcion
aciertos
obtuvo
modelo
httpsscikitlearnorgstablemodulesgeneratedsklearnneighbors
neighborhoodcomponentsanalysishtml
httpsscikitlearnorgstablemodulesgeneratedsklearnpipelinepipelinehtml
algoritmos
clasiﬁcacion
mencionado
marco
teorico
matriz
confusion
sı
metrica
sı
permite
realizar
evaluacion
acerca
como
desempeno
modelo
cada
clase
matriz
confusion
knearest
neighbors
graﬁco
pueden
observarse
diagonal
principal
dos
valores
valor
entero
representa
numero
aciertos
obtuvo
modelo
clase
valor
proporcional
mientras
debajo
encima
diagonal
encuentran
valores
observaciones
clasiﬁcadas
erroneamente
figura
matriz
confusion
k
nearest
neighbors
lado
graﬁco
resulta
interesante
analizar
curva
roc
re
ceiver
operating
characteristic
curva
roc
graﬁco
representa
per
formance
modelo
umbrales
clasiﬁcacion
curva
dibuja
base
dos
parametros
ratio
verdaderos
positivos
true
positive
rate
tpr
ratio
falsos
positivos
false
positive
rate
fpr
donde
tpr
sinonimo
recall
esta
dado
por
tpr
tp
tp
fn
fpr
encuentra
deﬁnido
por
fpr
fp
fp
tn
capitulo
clasiﬁcacion
malware
curva
tıpicamente
presenta
ratios
verdaderos
positivos
eje
y
ratio
falsos
positivos
eje
x
signiﬁca
esquina
izquierda
graﬁca
encuentra
punto
ıdeal
ratio
falsos
positivos
igual
cero
ratio
verdaderos
positivos
igual
tanto
cuanto
mas
grande
area
bajo
curva
area
under
the
curve
auc
mejor
bien
curvas
normalmente
utilizadas
clasiﬁcacion
binaria
po
sible
extender
curva
roc
area
roc
clasiﬁcacion
multiclases
utilizando
herramienta
scikitlearn
realizar
necesario
binarizar
salida
luego
clasiﬁcador
aprenda
predecir
cada
clase
otra
graﬁco
descripto
knearest
neighbours
puede
encontrar
ﬁgura
figura
roc
k
nearest
neighbors
random
forest
continuacion
realizo
implementacion
algoritmo
random
forest
ran
dom
forest
compone
ensamble
varios
arboles
decision
utiliza
bootstrapping
seleccion
aleatoria
conjunto
observaciones
reemplazo
varios
subconjuntos
aleatorios
dataset
considera
separacion
cada
nodo
arbol
decision
voto
promedio
mejorar
precision
prediccion
controlar
sobreajuste
overﬁtting
implementacion
implementacion
random
forest
llevaron
cabo
siguientes
pasos
leen
archivos
contienen
datos
preprocesados
explicados
ante
riormente
archivo
contiene
etiquetas
algoritmos
clasiﬁcacion
utilizando
librerıa
scikitlearn
separa
conjunto
datos
training
testing
proporcion
o
respectivamente
crea
instancia
clasiﬁcador
randomforestclassifier
parametros
valores
defecto
ﬁnalizado
paso
anterior
procede
realizar
fit
ajustando
mo
delo
acuerdo
datos
entrenamiento
provistos
paso
ﬁnal
sera
prediccion
sera
realizada
conjunto
prueba
permitira
luego
proyectar
resultados
matriz
confusion
precision
alcanzado
metricas
evaluacion
random
forest
precision
alcanzada
matriz
confu
sion
puede
observarse
graﬁco
mientras
curva
roc
encuentra
graﬁco
figura
matriz
confusion
random
forest
httpsscikitlearnorgstablemodulesgeneratedsklearnensemble
randomforestclassifierhtml
capitulo
clasiﬁcacion
malware
figura
roc
random
forest
xgboost
xgboost
extreme
gradient
boosting
implementaciones
algorit
mos
predictivos
supervisados
mas
utilizados
actualidad
menciono
marco
teorico
investigacion
xgboost
utiliza
principio
boosting
idea
booting
generar
varios
modelos
prediccion
debilessecuencialmente
ﬁn
generar
modelo
mas
fuerte
mayor
poder
predictivo
mayor
estabilidad
resultados
lograr
esto
modelo
emplea
algoritmo
optimizacion
denominado
gradient
descent
descenso
gradiente
cada
modelos
tomara
resultados
modelo
anterior
com
paraa
nuevo
modelo
mejores
resultados
entonces
utilizara
base
realizar
modiﬁcaciones
si
cambio
peores
resultados
regresa
mejor
modelo
anterior
mismo
sera
modiﬁcado
manera
diferente
proceso
iterativo
repetira
punto
diferencia
modelos
consecutivos
insigniﬁcante
indicarıa
llego
mejor
mo
delo
posible
llega
numero
iteraciones
maximas
deﬁnidas
usuario
implementacion
implementacion
xgboost
llevaron
cabo
siguientes
pasos
leen
archivos
contienen
datos
preprocesados
explicados
ante
riormente
archivo
contiene
etiquetas
httpsxgboostai
algoritmos
clasiﬁcacion
utilizando
librerıa
scikitlearn
separa
conjunto
datos
training
testing
proporcion
o
respectivamente
crea
instancia
clasiﬁcador
xgbclassifier
parame
tros
valores
defecto
xgbclassifier
implementacion
api
scikitlearn
clasiﬁcacion
xgboost
ﬁnalizado
paso
anterior
procede
realizar
fit
ajustando
mo
delo
acuerdo
datos
entrenamiento
provistos
paso
ﬁnal
sera
prediccion
sera
realizada
conjunto
prueba
permitira
luego
proyectar
resultados
matriz
confusion
precision
logrado
metricas
evaluacion
utilizacion
xgboost
logro
precision
clasiﬁca
cion
matriz
confusion
puede
verse
ﬁgura
mientras
curva
roc
observa
ﬁgura
figura
matriz
confusion
xgboost
httpsxgboostreadthedocsioenlatestpythonpython_apihtmlhighlight
xgbclassifierxgboostxgbclassifier
capitulo
clasiﬁcacion
malware
figura
roc
xgboost
artiﬁcial
neural
networks
artiﬁcial
neural
networks
redes
neuronales
artiﬁciales
construyen
simples
elementos
llamados
neuronas
cuales
toman
valor
real
multiplican
peso
ejecutan
traves
funciones
activacion
lineales
mediante
construccion
multiples
capas
neuronas
cada
cuales
recibe
parte
variables
entrada
cuyos
resultados
luego
seran
pasados
siguientes
capas
red
puede
ser
capaz
aprender
funciones
realmente
complejas
teorica
mente
red
neuronal
sera
capaz
aprender
forma
cualquier
funcion
simplemente
darle
suﬁciente
poder
computacional
implementacion
implementacion
artiﬁcial
neural
networks
llevo
cabo
utilizando
herramienta
tensorﬂow
integrado
api
embebida
keras
tensorﬂow
bi
blioteca
software
codigo
abierto
computacion
numerica
utiliza
gra
fos
ﬂujo
datos
nodos
grafos
representan
operaciones
matematicas
mientras
aristas
representan
matrices
datos
multidimensionales
ten
sores
comunicadas
ellos
disenado
originalmente
interfaz
expresar
implementar
algoritmos
machine
learning
cuales
destacan
deep
neural
networks
redes
neuronales
profundas
mientras
keras
api
alto
nivel
tensorﬂow
construir
entrenar
modelos
aprendizaje
profundo
interfaz
sencilla
resulta
facil
usar
implementar
pasos
implementacion
siguientes
httpswwwtensorfloworgoverview
httpswwwtensorfloworgguidekerashles
algoritmos
clasiﬁcacion
lee
archivo
contiene
datos
preprocesados
explicados
anteriormen
te
archivo
contiene
etiquetas
labels
caso
red
neuronal
vez
leıdo
archivo
labels
debio
realizar
mismo
encoding
datos
red
ası
requiere
utilizando
funcion
onehotencoder
provista
scikitlearn
posible
codiﬁcar
va
lores
categoricos
arreglo
numerico
onehot
tambien
conocido
oneofk
dummy
variable
esquema
codiﬁcado
encoding
crea
co
lumna
binaria
cada
categorıa
capaz
devolver
matriz
dispersa
arreglo
denso
segun
requiera
caso
opto
arreglo
denso
vez
realizado
encoding
labels
utilizando
librerıa
scikitlearn
separa
conjunto
datos
training
testing
proporcion
o
respectivamente
continuacion
creo
modelo
capas
componen
ademas
debera
tambien
deﬁnir
cuantas
salidas
tendra
red
caso
clases
distintas
red
contruyo
dos
capas
neronas
cada
una
ambas
funcion
activacion
relu
rectiﬁed
linear
unit
capa
salida
funcion
activacion
softmax
siguiente
paso
consistio
compilar
modelo
parametros
ajustados
optimizador
utilizo
adam
la
optimizacion
adam
metodo
descenso
gradiente
estocastico
basa
estimacion
adaptativa
momentos
primer
segundo
orden
funcion
perdida
loss
deﬁnio
categoricalcrossentropy
se
utiliza
funcion
crossentropy
loss
mas
dos
clases
metrica
indicamos
accuracy
finalizada
etapa
anterior
procedio
realizar
ﬁt
ajustando
modelo
descripto
paso
ﬁnal
sera
prediccion
sera
realizada
conjunto
prueba
permitira
luego
proyectar
resultados
matriz
confusion
precision
logrado
metricas
evaluacion
precision
alcanzada
modelo
propuesto
artiﬁcial
neural
network
gaﬁcos
muestran
como
comporto
modelo
cuanto
precision
accuracy
perdida
loss
respectivamente
debe
recordar
httpswwwtensorfloworgapi_docspythontfkerasoptimizersadam
httpswwwtensorfloworgapi_docspythontfkeraslosses
categoricalcrossentropy
capitulo
clasiﬁcacion
malware
precision
metrica
indicara
tan
acertada
prediccion
mode
comparado
valores
reales
datos
el
valor
representa
debe
leer
porcentaje
mientras
funcion
perdida
retornara
valor
real
calcula
fase
entrenamiento
validacion
indi
cara
tan
bien
tan
pobre
comporto
modelo
luego
cada
iteracion
cuanto
mas
pequeno
dicho
valor
mejor
resultara
modelo
figura
precision
accuracy
modelo
clasiﬁcacion
fa
milias
figura
perdida
loss
modelo
clasiﬁcacion
familias
graﬁco
encuentra
matriz
confusion
representan
todas
predicciones
realizo
modelo
datos
prueba
que
tan
acertadas
fueron
comparaciones
conclusiones
figura
matriz
confusion
artiﬁcial
neural
networks
ultimo
graﬁco
representa
curva
roc
red
figura
roc
artiﬁcial
neural
networks
comparaciones
conclusiones
primera
instancia
implemento
modelo
knearest
neighbors
dar
luego
lugar
mas
complejos
ejemplo
artiﬁcial
neural
network
capitulo
clasiﬁcacion
malware
knearest
neighbors
junto
neighborhood
component
analysis
demos
trado
ser
buena
opcion
alcanzando
valores
optimos
casi
par
cual
quier
implementacion
mas
compleja
yo
costosa
neighborhood
com
ponent
analysis
logro
darle
knearest
neighbors
cierta
mejora
algoritmo
sı
mismo
habıa
alcanzado
buenos
resultados
agregandole
costo
compu
tacional
practicamente
imperceptible
continuacion
modo
comparativo
decidio
implementar
metodo
en
samble
caso
random
forest
poderosos
algoritmos
pueden
resul
tar
buena
alternativa
tienden
realizar
buena
generaliza
cion
datos
evitar
overﬁtting
implementarlo
resulto
bastante
simple
logrando
precision
rango
cercano
tiempo
ejecu
cion
bueno
implementacion
algoritmo
gradiente
arboles
reforzados
vuelto
popular
ampliamente
utilizada
comunidad
cientıﬁcos
da
tos
ultimos
anos
xgboost
robusta
eﬁciente
implementacion
codigo
abierto
demostrado
realmente
altura
aquello
creado
velocidad
rendimiento
forman
parte
caracterısticas
prin
cipales
internamente
datos
estructura
matriz
llamada
dmatrix
encuentra
optimizada
uso
memoria
velocidad
entrenamiento
popularidad
buena
fama
motivo
utilizarlo
clasiﬁcacion
familias
malware
investigacion
logro
precision
cercana
tiempo
ejecucion
mas
aceptable
ultimo
opto
desarrollar
red
neuronal
popularidad
porque
basicamente
capaces
resolver
casi
cualquier
problema
simpliﬁ
car
hacer
mas
rapida
sencilla
implementacion
utilizo
framework
tensor
ﬂow
framework
integrado
api
keras
capaces
proveer
interfaz
sencilla
facil
usar
implementacion
artiﬁcal
neural
networks
deep
neural
networks
red
neuronal
fue
investigacion
logro
precision
mas
alta
excelente
performace
tanto
podrıa
decirse
todas
implementaciones
resultados
ser
opciones
mas
validas
pueden
ser
cuenta
clasiﬁcacion
diferentes
familias
malware
haciendo
necesario
llevar
cabo
costosa
implementacion
red
neuronal
clasiﬁcar
muestras
posible
obtener
practicamente
mismos
resultados
cualquiera
algoritmos
clasiﬁcacion
mencionados
investigacion
capitulo
deteccion
malware
capıtulo
deﬁnio
cuales
pasos
realizados
llevar
cabo
clasiﬁcacion
distintas
familias
malware
continuacion
buscara
im
plementar
sistema
clasiﬁcacion
binario
capaz
determinar
archivo
maligno
benigno
presente
capıtulo
explicara
proceso
clasiﬁcacion
realizo
determinar
archivo
puede
ser
considerado
maligno
no
ello
comen
zara
describiendo
que
consistieron
tareas
obtencion
desensamblado
archivos
pasos
generar
dataset
etapas
preprocesamiento
mismo
finalmente
abordaran
describiran
soluciones
propuestas
obtencion
desensamblado
archivos
benignos
problema
deteccion
malware
puede
ser
visto
clasiﬁcacion
binaria
debe
determinar
dado
archivo
conocido
algoritmo
este
capaz
determinar
mismo
detectado
malware
tanto
sera
necesario
contar
muestras
aplicaciones
consideradas
benignas
sitios
cnet
sourceforge
descargaron
total
aplicaciones
livianas
vez
obtenidas
todas
aplicaciones
procedio
realizarles
des
ensamblado
ello
utilizo
aplicacion
interactive
disassembler
mas
conocida
acronimo
ida
desensamblador
generalmente
utilizado
realizar
ingenierıa
inversa
ejecutables
y
modo
poder
convertir
apli
cacion
archivo
asm
ser
necesario
bytes
formatos
requeriran
comenzar
proceso
extraccion
informacion
descripto
capıtulo
httpsdownloadcnetcom
httpssourceforgenet
httpswwwhexrayscomproductsidasupportdownload_freeware
capitulo
deteccion
malware
junto
muestras
correspondientes
archivos
benignos
seleccionaron
numero
igual
malwares
provenientes
dataset
nueve
familias
tanto
total
muestras
realizo
proceso
minerıa
datos
encontro
conformado
total
archivos
cuales
corresponden
archivos
benignos
archivos
malignos
generacion
nuevo
dataset
forma
analoga
trabajo
realizado
clasiﬁcacion
familias
pasos
correspondientes
extraccion
informacion
mencionados
capıtulo
debieron
ser
realizados
nuevamente
generar
nuevo
dataset
analisis
exploratorio
preprocesamiento
dataset
creado
procedio
realizar
analisis
exploratorio
prepro
cesamiento
datos
mismo
modo
hizo
dataset
malwares
cuanto
analisis
exploratorio
estudio
nuevamente
correlacion
pearson
puede
ver
graﬁca
y
analogo
sucedido
clasiﬁcacion
familias
pueden
observar
correlaciones
mas
altas
ngramas
similares
ejemplo
mov
sub
mov
sub
mov
analisis
exploratorio
preprocesamiento
figura
correlacion
pearson
clasiﬁcacion
malwareno
malware
lado
preprocesamiento
explico
capıtulo
consistio
tratamiento
datos
nulos
faltantes
determinar
importancia
variables
estandarizar
datos
ultimo
seleccion
extraccion
variables
tratamiento
valores
nulos
faltantes
tomaron
mismas
deci
siones
caso
dataset
malware
completando
valores
faltantes
ceros
cuanto
calculo
importancia
variables
mismo
realizo
utili
zando
random
forest
graﬁco
puede
observar
resultado
aplicar
dicho
proceso
comparamos
graﬁco
podemos
ver
diferentes
capitulo
deteccion
malware
variables
allı
consideradas
importantes
aquı
incluso
proba
blemente
encuentren
presentes
excepcion
variable
header
lidera
lista
ambos
casos
diferencias
ocurren
extrajo
informa
cion
conjunto
datos
inicial
los
samples
malware
proceso
realizo
minerıa
determino
ciertas
caracterısticas
comunes
ellas
mientras
realizar
proceso
nuevamente
considerando
lugar
archivos
benignos
caracterısticas
naturalmente
cambiaron
figura
importancia
variables
clasiﬁcacion
malwa
reno
malware
respecto
seleccion
atributos
procedio
misma
manera
caso
clasiﬁcacion
familias
aplicar
proceso
seleccion
redujo
dataset
compuesto
columnas
puede
ser
considerado
reduccion
signiﬁcativa
igual
caso
dataset
malwares
realizo
escalado
datos
utilizando
escala
estandar
ultimo
aplico
proceso
extraccion
variables
utilizando
kernel
prin
cipal
component
analysis
mas
conocido
acronimo
kpca
graﬁco
puede
observarse
varıa
varianza
medida
aumenta
numero
com
ponentes
caso
componentes
posible
explicar
va
rianza
implementacion
solucion
figura
analisis
componentes
kernel
pca
clasi
ﬁcacion
malwareno
malware
implementacion
solucion
objetivo
implementacion
consiste
poder
determinar
archivo
puede
ser
clasiﬁcado
malware
que
grado
precision
ello
opto
llevar
cabo
implementacion
artiﬁcal
neural
network
esta
mejor
desempeno
obtuvo
clasiﬁcacion
familias
malware
modelo
base
ello
comenzo
implementando
red
neuronal
respetando
misma
conﬁ
guracion
utilizo
clasiﬁcacion
familias
vez
clasiﬁcacion
serıa
binaria
malwareno
malware
red
logro
buen
resultado
precision
apenas
superior
embargo
observamos
graﬁcos
puede
ver
como
modelo
esta
precision
mayor
duran
entrenamiento
mientras
datos
prueba
obtiene
valores
inferiores
podrıa
ser
claro
indicio
modelo
esta
sobreajustando
overﬁtting
valores
datos
entrenamiento
capitulo
deteccion
malware
figura
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
figura
perdida
loss
modelo
clasiﬁcacion
malwareno
malware
tratamiento
sobreajuste
overﬁtting
menciono
previamente
modelo
esta
sobreajustando
valores
datos
entrenamiento
existen
varias
alternativas
pueden
llevar
cabo
minimizar
incluso
eliminar
problema
continuacion
iran
mencionando
explicando
que
consisten
cada
como
aplicadas
complejidad
modelo
formas
mas
simples
evitar
overﬁtting
simpliﬁcando
com
plejidad
modelo
reduciendo
numero
capas
componen
implementacion
solucion
forma
resolver
problema
puede
ser
comenzando
creacion
modelo
simple
unas
pocas
capas
luego
ir
agregando
gradualmente
mas
capas
llegar
modelo
mejor
desempeno
tenga
tensorﬂow
junto
he
rramienta
interactiva
visualizacion
tensorboard
provee
varias
herramientas
ayudan
proceso
identiﬁcar
mejor
experimento
conjunto
hiperparame
tros
mas
prometedor
tasa
aprendizaje
learning
rate
muchas
veces
modelos
responden
mejor
tasa
aprendizaje
learning
rate
optimizadores
mas
baja
entrenamiento
posible
bien
establecer
tasa
ﬁja
inferior
previamente
deﬁnida
ir
decrementandola
gradualmente
medida
avanza
entrenamiento
experimento
ultima
solucion
mejor
resulto
parada
temprana
early
stop
manera
prevenir
overﬁtting
deteniendo
manera
temprana
proce
so
entrenamiento
lugar
entrenar
cierto
numero
epochs
proceso
detiene
tan
pronto
perdida
loss
funcion
este
monitoreando
eleve
que
seguir
entrenando
modelo
solo
empeorarıa
ello
uti
lizo
utilidad
provista
api
keras
callbacksearlystopping
permite
parametrizar
monitoreo
metrica
desea
paciencia
tendra
misma
detener
entrenamiento
regularizacion
pesos
weight
regularization
manera
comun
mitigar
overﬁtting
imponiendo
restricciones
cuanto
complejidad
red
forzando
pesos
solo
tomen
valores
pe
quenos
hace
distribucion
valores
pesos
mas
regular
denomina
weight
regualrization
logra
agregando
funcion
perdida
red
penalizacion
asociada
tener
grandes
pesos
pueden
ser
divididas
en
l
regularization
donde
costo
adicionado
proporcional
valor
abso
luto
coeﬁcientes
pesos
l
regularization
donde
costo
adicionado
proporcional
cuadra
do
valor
coeﬁcientes
pesos
modelo
probado
conﬁgurado
modelo
tomara
dis
tintos
valores
regularizacion
l
httpswwwtensorfloworgtensorboardhles
capitulo
deteccion
malware
agregado
dropout
dropout
tecnicas
mas
efectivas
mas
comunmente
utilizados
regularizacion
justiﬁcacion
detras
tecnica
indica
que
nodos
indivi
duales
red
pueden
conﬁar
salida
nodos
cada
nodo
debe
generar
propios
features
salida
utiles
sı
mismos
tanto
dropout
aplicado
capa
consiste
quitar
llevarlo
cero
manera
aleatoria
cierto
numero
features
salida
capa
entrenamiento
uso
api
mencionada
usuario
puede
establecer
proporcion
dropout
rate
valores
seran
quitados
todas
estrategias
combinadas
red
realizar
ajuste
hiperparametros
resultado
aplicar
dicho
proceso
puede
verse
graﬁco
allı
observa
listado
todas
pruebas
realizadas
precision
alcanzada
partir
resultados
tomaron
decisiones
diseno
artiﬁcial
neural
network
ayudaran
mejorar
funcionamiento
misma
implementacion
solucion
figura
conﬁguracion
hiper
parametros
clasiﬁcacion
malwareno
malware
capitulo
deteccion
malware
resultados
obtenidos
vez
obtenido
modelo
parametros
optimizados
realizaron
nue
vamente
pruebas
clasiﬁcacion
binaria
vez
modelo
obtuvo
precision
apenas
superior
bien
logro
mejora
sustancial
respec
to
modelo
base
alrededor
resultados
siguen
ser
buenos
observa
graﬁca
puede
apreciar
que
aunque
logrado
reducir
ligeramente
sobreajuste
este
todavıa
encuentra
presente
figura
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
figura
perdida
accuracy
modelo
clasiﬁcacion
malwa
reno
malware
continuacion
encuentra
graﬁca
muestra
matriz
confusion
dio
resultado
red
implementacion
solucion
figura
matriz
consuﬁcon
modelo
clasiﬁcacion
malwareno
malware
mientras
curva
roc
encuentra
graﬁcada
ﬁgura
figura
roc
modelo
clasiﬁcacion
malwareno
malware
xgboost
solucion
alternativa
seccion
anterior
vio
implementacion
red
neuronal
tu
vo
buen
desempeno
realizando
clasiﬁcacion
binaria
dado
posible
reducir
completamente
overﬁtting
continuacion
utilizara
algoritmo
ensamble
xgboost
estos
igual
random
forest
suelen
realizar
buenas
generalizaciones
modo
evitar
problema
overﬁtting
modelado
igual
caso
red
neuronal
modelo
base
xgboost
ser
ajustado
hiperparametros
tampoco
logro
alcanzar
buena
preci
sion
modelo
implemento
utilizando
librerıa
scikit
learn
cuenta
wrapper
interface
xgboost
interfaz
permite
crear
modelo
parametri
zarlo
segun
desee
continuacion
mencionaran
parametros
modiﬁcados
investigacion
learning
rate
indica
velocidad
aprendera
modelo
logrando
mas
robusto
ir
encogiendo
pesos
cada
iteracion
capitulo
deteccion
malware
max
depth
parametro
determinara
profundidad
puede
tomar
arbol
subsample
valor
denota
fraccion
samples
u
observaciones
seran
tomadas
manera
aleatoria
cada
arbol
nestimators
valor
determina
numero
arboles
o
rondas
tendra
modelo
ademas
utilizo
tambien
parada
temprana
early
stopping
rounds
entrenamiento
disminuir
overﬁtting
resultados
obtenidos
implementacion
modelo
logrado
cierta
mejora
respecto
red
neu
ronal
artiﬁcial
alcanzando
precision
continuacion
encuentran
graﬁcos
correspondientes
precision
lograda
entrenamiento
pruebas
igual
graﬁca
error
clasiﬁcacion
figura
precision
accuracy
modelo
clasiﬁcacion
malwareno
malware
utilizando
xgboost
implementacion
solucion
figura
error
modelo
clasiﬁcacion
malwareno
malwa
re
utilizando
xgboost
matriz
confusion
puede
observarse
ﬁgura
graﬁca
roc
figura
matriz
confusion
clasiﬁcacion
malwareno
malware
utilizando
xgboost
figura
roc
clasiﬁcacion
malwareno
malware
utilizando
xgboost
capitulo
deteccion
malware
comparaciones
conclusiones
comenzo
implementando
red
neuronal
similar
utilizada
clasiﬁcacion
familias
malware
red
modelo
base
arrojo
buenos
resultados
motivo
intentar
ajustar
hiperparametros
determinar
manera
posible
lograr
mejora
modelo
predicciones
ello
implementaron
varias
estrategias
ayudarıan
dicho
modelo
lograr
mejor
desempeno
proceso
realizo
combinando
diversas
maneras
distintos
parametros
modelo
luego
determinar
mediante
uso
alguna
metrica
opcion
produce
mejores
resultados
hecho
esto
modiﬁco
modelo
inicial
incorporando
parame
tros
procedio
correr
nuevamente
pruebas
clasiﬁcacion
bien
logro
cierta
mejora
precision
reducir
overﬁtting
resultado
alcanzo
valores
aceptables
lado
alternativa
red
neuronal
llevo
cabo
implemen
tacion
xgboost
modo
evaluar
posible
mejorar
precision
prediccion
alcanzada
red
neuronal
modelo
logro
cierta
mejora
respecto
red
precision
superior
embargo
valor
aun
sigue
bajo
identiﬁcaron
menos
tres
problemas
pueden
impactar
negativamente
performance
ambos
modelos
lado
posible
garantizar
sam
ples
benignos
realmente
benignos
debe
archivos
considerados
benignos
descargados
sitios
pueden
dar
fe
legitimidad
lado
encuentra
heterogeneidad
archivos
dispares
sı
programas
pueden
variar
plugin
editor
texto
ultimo
cabe
mencionar
tamano
dataset
utilizado
solo
dispuso
total
samples
mientras
red
clasiﬁcacion
familias
contaba
total
superior
samples
capitulo
conclusiones
tecnologıas
informacion
facilitan
vida
personas
sinnume
ro
actividades
incluyendo
comunicaciones
comercio
viajes
estudio
trabajo
muchas
otras
hackers
tambien
utilizan
tecnologıa
lograr
propositos
aprovechando
vulnerabilidades
sistemas
robar
informacion
obtener
acceso
cualquier
actividad
ﬁn
malicioso
metodos
tradicionales
deteccion
utilizados
antivirus
resultan
efectivos
avances
evolucion
ataques
expertos
ciencia
datos
junto
comunidad
anti
malware
aunado
esfuerzos
encontrar
solucion
pueda
hacer
frente
problematica
alento
empresas
dedicadas
industria
software
antivirus
comenzar
utilizar
tecnicas
machine
learning
deep
learning
desarrollo
produc
tos
motivados
avances
logrados
campo
decidio
dar
inicio
investigacion
intentar
poner
prueba
dichas
aﬁrmaciones
modo
lugar
extenso
numero
tareas
data
mining
dedicadas
procesar
conjunto
datos
comprendido
cerca
once
mil
archivos
malware
formato
asm
bytes
objetivo
extraer
atributos
estipu
laron
podrıan
llegar
ser
representativos
comportamiento
ﬁsonomıa
programas
etapa
investigacion
mas
demandante
requiriendo
solo
es
critura
procesos
extraer
datos
necesarios
sino
tambien
construccion
herramientas
permitieran
visualizar
informacion
obtenida
cada
etapa
ﬁn
validar
resultados
obtenidos
detectar
errores
manera
temprana
apoyar
toma
decisiones
cuestiones
establecimiento
punto
corte
seleccion
atributos
relevantes
capitulo
conclusiones
vez
consolidados
datos
dataset
unico
fase
preprocesamiento
depurado
permitio
evaluar
distintos
aspectos
datos
recabados
reaﬁr
mando
ası
suposiciones
hechas
comienzo
proceso
data
mining
importancia
tamanos
archivos
tambien
permitio
descubrir
median
estudio
relevancia
correlacion
variables
relaciones
subyacentes
descartar
features
habıamos
supuesto
podrıan
ser
utilidad
snapshots
primeros
bytes
archivos
asm
ası
mismo
utilizacion
distintas
tecnicas
permitio
considerable
reduccion
dimensionalidad
problema
sacriﬁcio
practicamente
insigniﬁcante
performance
finalmente
elaboracion
distintos
modelos
machine
learning
cla
siﬁcacion
familias
malware
permitio
poner
prueba
eﬁcacia
datos
extraıdos
obteniendo
resultados
superiores
precision
ca
sos
incluso
superiores
red
neuronal
siquiera
tener
realizar
tuning
parametros
lado
sobreajuste
observado
modelos
clasiﬁcacion
binaria
llevo
estudio
mas
profundos
distintas
alternativas
resolver
problema
aunque
deﬁnitiva
tamano
pequeno
conjunto
datos
resulto
ser
inconveniente
imposible
eludir
conclusion
cuenta
resultados
obtenidos
posible
aﬁrmar
utilizacion
tecnicas
data
mining
machine
learning
clasiﬁcar
familias
malware
resultado
efectivas
cuanto
clasiﬁcacion
binaria
seguros
que
contar
conjunto
datos
considerablemente
mas
grande
en
orden
miles
realizar
entrenamiento
algoritmos
podrıan
lograr
resultados
ampliamente
superiores
alcanzados
trabajo
capitulo
trabajos
futuros
continuacion
enunciaran
caracterısticas
podrıan
resultar
intere
santes
abordar
menos
ser
cuenta
investigacion
futura
seguir
lınea
ejecucion
jumps
momento
extraer
codigos
operacion
instrucciones
encuentren
dentro
loops
ejecutaran
multiples
veces
solo
una
explorar
distintos
valores
corte
momento
seleccionar
features
relevantes
conjunto
datos
promediar
longitud
secciones
archivos
asm
lugar
solo
contar
cantidad
ocurrencias
formar
ngramas
contenido
archivos
bytes
extender
clasiﬁcacion
incluyendo
mas
familias
malwares
entrenar
algoritmos
clasiﬁcacion
binaria
dataset
considerable
mente
mayor
utilizado
poder
garantizar
archivos
benignos
realmente
benignos
contar
dataset
mas
equilibrados
cantidades
archivos
componen
cada
clase
sen
mas
parejas
buscar
nuevas
tecnicas
puedan
reducir
overﬁtting
clasiﬁcacion
binaria
establecer
mejor
ajuste
hiperparametros
algoritmos
clasiﬁ
cacion
binaria
implementar
red
neuronal
profunda
mas
compleja
clasiﬁcacion
imagenes
escala
grises
bibliografıa
tushar
sharma
dipanjan
sarkar
raghav
bali
practical
machine
learning
with
python
bangalore
karnataka
india
apress
christopher
c
elisan
advanced
malware
analysis
unidos
mc
graw
hill
education
mark
a
hall
christopher
j
pal
ian
hwitten
eibe
frank
data
mining
practi
cal
machine
learning
tools
and
techniques
cambridge
miami
unidos
morgan
kaufmann
t
hastie
j
gareth
d
witten
r
tibshirani
an
introduction
to
statistical
lear
ning
new
york
springer
matthew
kirk
thoughtful
machine
learning
with
python
sebastopol
california
unidos
oreilly
h
liu
m
cocea
granular
computing
based
machine
learning
suiza
springer
t
mitchell
machine
learning
mcgraw
hill
stuart
j
russell
peter
norvig
artiﬁcial
intelligent
modern
approach
thrid
edition
inglaterra
pearson
scikitlearn
scikitlearn
tutorials
httpsscikitlearnorgstabletutorial
indexhtml
m
sikorski
a
honig
practical
malware
analysis
san
francisco
starch
press
mark
stamp
introduction
to
machine
learning
with
applications
in
information
security
boca
raton
florida
crc
press
tensorﬂow
tensorﬂow
tutorials
httpswwwtensorfloworgtutorials
yehezkel
s
resheff
itay
lieder
tom
hope
learning
tensorﬂow
sebastopol
california
unidos
oreilly
jose
unpingco
python
for
probability
statistics
and
machine
learning
san
die
go
california
unidos
springer
jake
vanderplas
python
data
science
handbook
sebastopol
california
unidos
oreilly
bibliografia
university
of
virginia
computer
science
x
assembly
guide
httpwww
csvirginiaeduevanscsguidesxhtml
summet
dua
xian
du
data
mining
and
machine
learning
in
cybersecurity
boca
raton
florida
unidos
crc
press